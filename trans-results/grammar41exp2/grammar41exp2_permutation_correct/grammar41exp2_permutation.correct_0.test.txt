2024-12-19 06:31:15 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2024-12-19 06:31:17 | INFO | fairseq_cli.eval_lm | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'checkpoints/grammar41exp2_permutation/0-transformer/checkpoint_best.pt', 'post_process': None, 'quiet': True, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': True, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': None, 'task': {'_name': 'language_modeling', 'data': 'data-bin/grammar41exp2_permutation/correct_0-dataset', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2024-12-19 06:31:17 | INFO | fairseq.tasks.language_modeling | dictionary: 1136 types
2024-12-19 06:31:17 | INFO | fairseq_cli.eval_lm | loading model(s) from checkpoints/grammar41exp2_permutation/0-transformer/checkpoint_best.pt
/workspace/artificial-languages/fairseq/fairseq/checkpoint_utils.py:340: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(f, map_location=torch.device("cpu"))
2024-12-19 06:31:21 | INFO | fairseq_cli.eval_lm | num. model params: 10,038,784
2024-12-19 06:31:21 | INFO | fairseq.data.data_utils | loaded 236 examples from: data-bin/grammar41exp2_permutation/correct_0-dataset/test
2024-12-19 06:31:21 | INFO | fairseq_cli.eval_lm | data-bin/grammar41exp2_permutation/correct_0-dataset test 2 examples
2024-12-19 06:31:21 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-12-19 06:31:21 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True
2024-12-19 06:31:21 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False
2024-12-19 06:31:21 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1
/opt/conda/envs/art/lib/python3.9/site-packages/torch/nn/functional.py:5849: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2024-12-19 06:31:23 | INFO | fairseq_cli.eval_lm | 1 </s> [-1.396001]	pitchfork [-17.825590]	an [-7.464957]	</s> [-2.913079]	pitchfork [-17.295708]	a [-9.067998]	</s> [-1.849182]	pitchfork [-17.400133]	the [-9.206141]	</s> [-2.208189]	sneeze [-16.820856]	an [-8.158491]	</s> [-2.909266]	sneeze [-17.008965]	the [-9.190451]	</s> [-2.226306]	mountebank [-18.428442]	one [-9.228220]	</s> [-2.000065]	mountebank [-18.376745]	an [-8.567390]	</s> [-3.100309]	key [-18.167631]	an [-8.926292]	</s> [-3.154824]	close [-17.151955]	the [-9.092502]	</s> [-2.171553]	close [-17.304281]	an [-9.005094]	</s> [-3.010321]	number [-18.055012]	an [-8.324057]	</s> [-2.788826]	number [-18.092054]	hundred [-8.620541]	</s> [-2.611793]	rediscover [-17.911222]	hundred [-9.198603]	</s> [-2.814459]	rediscover [-18.172882]	one [-9.233543]	</s> [-2.081421]	rediscover [-17.977018]	my [-8.828983]	</s> [-2.812870]	outbalance [-17.158943]	one [-9.034134]	</s> [-1.891930]	outbalance [-17.273939]	my [-8.373178]	</s> [-2.889268]	circumcise [-17.888758]	my [-8.912541]	</s> [-2.752149]	power [-16.603024]	the [-9.906519]	</s> [-1.758644]	decentralize [-18.397398]	an [-8.174664]	</s> [-2.956882]	decentralize [-18.408737]	hundred [-8.528776]	</s> [-3.478906]	decentralize [-18.391659]	one [-8.606290]	</s> [-2.377617]	get [-17.416082]	the [-9.801032]	</s> [-2.630589]	get [-17.503340]	one [-9.141099]	</s> [-2.342854]	wheelbarrow [-18.550901]	your [-9.460655]	</s> [-2.172343]	wheelbarrow [-18.469027]	hundred [-9.393514]	</s> [-3.047230]	booby [-18.116310]	the [-9.188830]	</s> [-2.220433]	booby [-17.996346]	hundred [-8.966058]	</s> [-3.209252]	booby [-17.882952]	an [-8.338383]	</s> [-3.042294]	interchange [-18.529232]	one [-9.782112]	</s> [-2.431452]	interchange [-18.696543]	your [-10.525081]	</s> [-2.645263]	keep [-17.730103]	one [-9.112732]	</s> [-2.136828]	keep [-17.551449]	my [-9.507446]	</s> [-2.910592]	keep [-17.652861]	a [-9.156939]	</s> [-2.246572]	hero [-17.845354]	hundred [-9.074775]	</s> [-3.225603]	hero [-17.803530]	a [-8.426503]	</s> [-2.207775]	constrict [-17.982967]	a [-8.682421]	</s> [-2.277865]	constrict [-18.066402]	one [-8.862292]	</s> [-2.339962]	weasel [-18.101665]	one [-9.080081]	</s> [-2.219007]	intermarry [-17.688370]	a [-8.764731]	</s> [-1.984210]	intermarry [-17.644901]	my [-8.707871]	</s> [-2.534977]	intermarry [-17.392588]	one [-9.095260]	</s> [-2.173805]	intermarry [-17.463037]	your [-9.747066]	</s> [-2.326188]	prejudice [-17.899448]	a [-8.341316]	</s> [-2.135412]	secularize [-18.440777]	one [-9.003115]	</s> [-2.332301]	rustle [-17.959442]	an [-8.697223]	</s> [-2.957100]	rustle [-17.943245]	your [-9.917375]	</s> [-2.353140]	rustle [-17.927925]	one [-9.086067]	</s> [-1.920440]	slap [-17.507326]	my [-8.431036]	</s> [-2.341673]	slap [-17.396471]	hundred [-8.473741]	</s> [-2.964372]	break [-17.938766]	one [-8.772822]	</s> [-2.302881]	break [-18.005468]	my [-8.821067]	</s> [-2.766396]	ginger [-17.433134]	hundred [-9.354213]	</s> [-2.909079]	ginger [-17.274506]	a [-9.141993]	</s> [-1.881185]	ginger [-17.429634]	your [-9.850245]	</s> [-2.722908]	soft [-16.226595]	an [-8.624516]	</s> [-3.202098]	jeopardize [-18.173517]	your [-9.704734]	</s> [-2.532555]	jeopardize [-17.998144]	the [-9.632984]	</s> [-2.029160]	influence [-17.883715]	my [-9.361403]	</s> [-2.678476]	influence [-17.868614]	hundred [-9.653757]	</s> [-2.625977]	intercede [-17.253208]	an [-8.537199]	</s> [-2.869592]	intercede [-17.223642]	a [-8.452449]	</s> [-1.844773]	intercede [-17.242348]	one [-9.157268]	</s> [-1.907250]	intercede [-17.234003]	the [-9.375178]	</s> [-2.373472]	intercede [-17.250223]	your [-9.441328]	</s> [-2.591366]
2024-12-19 06:31:24 | INFO | fairseq_cli.eval_lm | 0 come [-14.659832]	a [-9.405047]	</s> [-1.574370]	come [-16.457184]	an [-8.653105]	</s> [-2.857427]	dehumanize [-16.824078]	hundred [-9.171118]	</s> [-2.808597]	dehumanize [-17.025246]	the [-9.590840]	</s> [-2.147790]	dehumanize [-17.088541]	an [-8.363985]	</s> [-2.974690]	dehumanize [-17.253172]	your [-9.310686]	</s> [-2.507805]	dehumanize [-17.327324]	my [-8.617381]	</s> [-2.758050]	vault [-16.766468]	a [-9.765338]	</s> [-2.226427]	square [-15.027915]	a [-8.522794]	</s> [-2.244992]	privilege [-17.466501]	an [-8.681753]	</s> [-3.107857]	privilege [-17.415112]	a [-9.302505]	</s> [-1.996016]	racketeer [-17.112844]	the [-9.746360]	</s> [-2.120377]	racketeer [-17.208113]	your [-10.180978]	</s> [-1.835557]	racketeer [-17.407801]	a [-9.557892]	</s> [-1.897188]	reemphasize [-17.077513]	an [-8.596104]	</s> [-2.985969]	rich [-14.684496]	an [-3.655275]	</s> [-2.975386]	rich [-15.016835]	hundred [-3.747777]	</s> [-3.285307]	pressurize [-16.985472]	one [-8.849937]	</s> [-2.336355]	pressurize [-17.034403]	a [-9.373502]	</s> [-1.884859]	blackguard [-17.916527]	a [-8.303059]	</s> [-1.801396]	blackguard [-17.846418]	your [-8.544835]	</s> [-2.665956]	give [-16.521353]	your [-7.795368]	</s> [-2.545303]	give [-16.459633]	hundred [-7.816276]	</s> [-3.020420]	give [-16.708147]	one [-7.292289]	</s> [-2.606207]	prescribe [-17.666609]	the [-9.460479]	</s> [-1.991303]	prescribe [-17.608702]	one [-9.134921]	</s> [-2.274212]	prescribe [-17.649551]	a [-9.076656]	</s> [-2.094460]	prescribe [-17.635557]	hundred [-9.221190]	</s> [-2.884073]	backtrack [-16.906229]	a [-8.730187]	</s> [-2.233095]	backtrack [-16.937353]	the [-9.180267]	</s> [-2.597697]	fall [-17.745562]	my [-8.736402]	</s> [-3.102918]	fall [-17.757614]	your [-9.702926]	</s> [-2.458624]	fall [-17.525465]	a [-8.551382]	</s> [-2.210416]	shove [-17.070362]	your [-9.604218]	</s> [-2.660104]	shove [-17.079426]	one [-8.919146]	</s> [-2.347459]	sweet [-13.603508]	my [-6.487520]	</s> [-2.902115]	sound [-16.747429]	hundred [-8.970487]	</s> [-3.395874]	sound [-16.996382]	one [-9.428885]	</s> [-2.426151]	sound [-16.795889]	the [-9.387029]	</s> [-2.370091]	hydroplane [-16.427429]	the [-9.339951]	</s> [-2.203891]	hydroplane [-16.610014]	your [-9.608344]	</s> [-2.204827]	hydroplane [-16.541460]	an [-9.001369]	</s> [-2.909257]	crosscheck [-17.211464]	one [-9.716789]	</s> [-2.097830]	crosscheck [-17.343924]	a [-8.989902]	</s> [-2.139789]	back [-15.803746]	an [-5.730193]	</s> [-3.133797]	back [-15.683959]	a [-6.733915]	</s> [-2.149364]	commercialize [-17.665348]	the [-9.630582]	</s> [-2.400825]	commercialize [-17.724169]	an [-9.170113]	</s> [-2.712936]	promenade [-17.269199]	hundred [-7.993072]	</s> [-2.546396]	promenade [-17.180624]	one [-7.995067]	</s> [-1.909613]	promenade [-17.276781]	the [-8.231127]	</s> [-2.275630]	promenade [-17.293821]	your [-9.159023]	</s> [-2.458694]	blind [-14.468821]	hundred [-3.844195]	</s> [-2.893635]	headquarter [-16.022226]	the [-9.632005]	</s> [-1.983584]	headquarter [-16.060814]	hundred [-9.607553]	</s> [-3.016971]	follow [-18.249716]	an [-8.699409]	</s> [-3.189997]	bump [-17.260822]	the [-9.471457]	</s> [-2.180315]	bump [-17.018349]	a [-8.862230]	</s> [-1.934532]	run [-14.942181]	your [-8.787020]	</s> [-2.407747]	run [-15.064717]	my [-7.513775]	</s> [-2.671349]	run [-15.079634]	an [-7.203686]	</s> [-2.737779]	commingle [-16.196020]	an [-8.857224]	</s> [-2.862049]	commingle [-16.223047]	the [-9.530275]	</s> [-1.828468]	choke [-17.281307]	one [-9.484208]	</s> [-2.399951]	choke [-17.181652]	hundred [-9.717668]	</s> [-3.033055]	choke [-17.270145]	an [-9.211518]	</s> [-2.903507]	choke [-17.223003]	my [-8.853269]	</s> [-2.719469]	medium [-13.097053]	a [-3.819609]	</s> [-1.962488]	medium [-13.268096]	the [-3.842080]	</s> [-2.245111]	medium [-13.284575]	hundred [-4.847727]	</s> [-3.386636]	intellectualize [-16.285198]	a [-8.618088]	</s> [-2.216547]	intellectualize [-16.155455]	my [-8.571795]	</s> [-2.753558]	folk [-16.898256]	an [-8.884359]	</s> [-3.294454]	folk [-17.042042]	a [-8.818208]	</s> [-2.322704]	folk [-17.128130]	the [-9.300240]	</s> [-2.203645]	folk [-17.056854]	one [-9.147457]	</s> [-1.345611]	dillydally [-17.355227]	a [-8.872261]	</s> [-1.798930]	dillydally [-17.494370]	one [-9.608430]	</s> [-2.012430]	crash [-17.558216]	my [-9.493895]	</s> [-2.674902]	crash [-17.605593]	a [-9.077073]	</s> [-2.111371]	crash [-17.596516]	one [-10.066935]	</s> [-1.976940]	crash [-17.746561]	hundred [-9.927196]	</s> [-3.168841]	listen [-17.285067]	my [-8.981933]	</s> [-3.266033]	listen [-17.201571]	an [-9.547027]	</s> [-3.375404]	provision [-17.671469]	hundred [-9.433791]	</s> [-2.660695]	provision [-17.573765]	one [-8.908896]	</s> [-1.796430]	provision [-17.822033]	a [-8.648880]	</s> [-1.927755]	criticise [-17.010342]	hundred [-9.349068]	</s> [-2.211757]	criticise [-17.120205]	one [-8.925364]	</s> [-1.995325]	track [-17.770788]	a [-8.798851]	</s> [-1.977397]	track [-17.740158]	your [-9.938579]	</s> [-2.424755]	track [-17.689888]	hundred [-8.749286]	</s> [-2.733368]	splash [-17.525526]	an [-8.967623]	</s> [-2.922521]	stanchion [-17.416651]	my [-9.161422]	</s> [-3.174673]	stanchion [-17.139984]	one [-9.526652]	</s> [-2.328310]	stanchion [-16.901779]	your [-10.000250]	</s> [-2.732163]	stanchion [-17.133900]	the [-9.696679]	</s> [-2.165050]	still [-17.255169]	hundred [-8.964828]	</s> [-3.160608]	still [-17.223343]	a [-8.187479]	</s> [-2.306979]	bucket [-17.568077]	my [-8.922881]	</s> [-2.786005]	carry [-16.949745]	a [-8.727782]	</s> [-2.188873]	carry [-17.095991]	an [-8.380703]	</s> [-3.205420]	gallivant [-17.844687]	a [-8.573438]	</s> [-2.272328]	gallivant [-17.978720]	your [-10.129738]	</s> [-2.790800]	interfere [-17.619997]	your [-10.336608]	</s> [-2.652564]	interfere [-17.696859]	one [-9.363883]	</s> [-2.210570]	interfere [-17.652086]	a [-8.572123]	</s> [-2.178064]	inconvenience [-16.399063]	hundred [-9.243147]	</s> [-3.002298]	replenish [-17.045486]	an [-8.863605]	</s> [-2.626226]	replenish [-17.035620]	one [-8.998240]	</s> [-2.046320]	replenish [-17.153296]	hundred [-9.373511]	</s> [-2.868379]	replenish [-17.166483]	a [-8.298966]	</s> [-2.036470]	disrespect [-16.615993]	hundred [-9.260894]	</s> [-2.733316]	disrespect [-16.756340]	a [-8.181430]	</s> [-2.100929]	disrespect [-16.510843]	an [-8.714909]	</s> [-2.804689]	disrespect [-16.698278]	my [-9.034422]	</s> [-2.786423]	rubber [-17.502190]	the [-8.734915]	</s> [-2.377005]	rubber [-17.611591]	your [-9.755537]	</s> [-2.888438]	undervalue [-17.315531]	a [-8.848205]	</s> [-2.269715]	undervalue [-17.243078]	one [-9.202065]	</s> [-2.398873]	apologize [-16.528261]	the [-9.861787]	</s> [-2.200758]	apologize [-16.641502]	your [-9.798054]	</s> [-2.543374]	mispronounce [-16.860966]	an [-9.073824]	</s> [-2.979249]	blaspheme [-17.282305]	one [-8.991800]	</s> [-2.145065]	spearhead [-16.958017]	one [-9.222511]	</s> [-1.969121]	overcharge [-17.722254]	a [-8.510509]	</s> [-2.066666]	demagnetise [-16.157534]	a [-8.739877]	</s> [-1.910332]	demagnetise [-16.108276]	an [-8.391138]	</s> [-2.532692]	demagnetise [-16.016247]	one [-8.607193]	</s> [-2.083931]	distemper [-17.651674]	hundred [-9.279043]	</s> [-2.574678]	distemper [-17.948551]	your [-10.044677]	</s> [-2.523964]	distemper [-17.792160]	a [-8.633420]	</s> [-2.090558]	distemper [-17.847126]	one [-8.702858]	</s> [-1.846950]	overemphasize [-16.891985]	the [-9.173156]	</s> [-2.368969]	overemphasize [-16.873339]	hundred [-9.288651]	</s> [-3.286302]	overemphasize [-16.774803]	my [-9.102531]	</s> [-2.710648]	overemphasize [-16.710085]	a [-8.604097]	</s> [-2.168976]	brutalize [-18.276548]	hundred [-8.394697]	</s> [-3.156308]	brutalize [-18.349688]	one [-9.084411]	</s> [-2.834541]	glamorize [-16.370552]	my [-8.654161]	</s> [-2.744217]	glamorize [-16.475649]	a [-8.872715]	</s> [-2.136796]	glamorize [-16.389088]	an [-8.889523]	</s> [-2.790363]	glamorize [-16.474726]	your [-9.410980]	</s> [-2.697351]	introvert [-18.616871]	my [-8.866059]	</s> [-2.700653]	introvert [-18.734983]	one [-8.839344]	</s> [-2.491278]	introvert [-18.719414]	the [-9.405540]	</s> [-2.416670]	revitalise [-16.530827]	the [-9.574086]	</s> [-2.542149]	revitalise [-16.292768]	a [-8.837016]	</s> [-2.344140]	revitalise [-16.332769]	an [-8.806309]	</s> [-2.815757]	revitalise [-16.527166]	your [-10.133339]	</s> [-2.562131]	bring [-17.408915]	the [-9.591799]	</s> [-2.123759]	bring [-17.565155]	your [-10.219179]	</s> [-2.591493]	overspecialize [-18.296728]	hundred [-7.866926]	</s> [-2.661034]	misbehave [-18.075363]	a [-9.194634]	</s> [-2.201543]	disembowel [-18.191088]	your [-10.030955]	</s> [-2.418594]	disembowel [-18.358351]	my [-9.174510]	</s> [-2.838401]	smooth [-18.171005]	one [-9.621428]	</s> [-2.326280]	smooth [-17.749611]	my [-8.795634]	</s> [-2.892244]	smooth [-17.603762]	your [-9.905439]	</s> [-2.549656]	misconduct [-16.893536]	hundred [-8.511369]	</s> [-2.587173]	misconduct [-16.832083]	your [-9.689683]	</s> [-2.494972]	misconduct [-16.895964]	my [-8.346207]	</s> [-2.720733]	misconduct [-16.736679]	the [-9.604639]	</s> [-2.078252]	predetermine [-17.261875]	the [-9.565823]	</s> [-2.416058]	predetermine [-17.226593]	hundred [-9.179725]	</s> [-2.871608]	predetermine [-17.144606]	my [-9.047594]	</s> [-2.753458]	burlesque [-16.745529]	one [-8.480886]	</s> [-2.174924]	burlesque [-16.694691]	an [-8.142843]	</s> [-2.399415]	dress [-17.448597]	the [-8.632478]	</s> [-1.935633]	dress [-17.482592]	a [-8.539180]	</s> [-1.730527]	dress [-17.556438]	my [-8.779140]
2024-12-19 06:31:24 | INFO | fairseq_cli.eval_lm | Evaluated 708 tokens in 0.9s (756.65 tokens/s)
2024-12-19 06:31:24 | INFO | fairseq_cli.eval_lm | Loss (base 2): 13.7338, Perplexity: 13623.06
