2024-12-19 08:12:09 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2024-12-19 08:12:11 | INFO | fairseq_cli.eval_lm | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'checkpoints/grammar41exp2_permutation/3-transformer/checkpoint_best.pt', 'post_process': None, 'quiet': True, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': True, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': None, 'task': {'_name': 'language_modeling', 'data': 'data-bin/grammar41exp2_permutation/correct_3-dataset', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2024-12-19 08:12:11 | INFO | fairseq.tasks.language_modeling | dictionary: 1136 types
2024-12-19 08:12:11 | INFO | fairseq_cli.eval_lm | loading model(s) from checkpoints/grammar41exp2_permutation/3-transformer/checkpoint_best.pt
/workspace/artificial-languages/fairseq/fairseq/checkpoint_utils.py:340: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(f, map_location=torch.device("cpu"))
2024-12-19 08:12:15 | INFO | fairseq_cli.eval_lm | num. model params: 10,038,784
2024-12-19 08:12:15 | INFO | fairseq.data.data_utils | loaded 236 examples from: data-bin/grammar41exp2_permutation/correct_3-dataset/test
2024-12-19 08:12:15 | INFO | fairseq_cli.eval_lm | data-bin/grammar41exp2_permutation/correct_3-dataset test 2 examples
2024-12-19 08:12:15 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-12-19 08:12:15 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True
2024-12-19 08:12:15 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False
2024-12-19 08:12:15 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1
/opt/conda/envs/art/lib/python3.9/site-packages/torch/nn/functional.py:5849: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2024-12-19 08:12:16 | INFO | fairseq_cli.eval_lm | 1 </s> [-0.930236]	blackguard [-18.704647]	one [-8.362939]	</s> [-2.166898]	buttonhole [-18.727835]	hundred [-8.906411]	</s> [-2.218356]	buttonhole [-18.583609]	the [-9.287992]	</s> [-1.389490]	buttonhole [-18.545376]	your [-8.756402]	</s> [-2.101578]	privilege [-17.396055]	hundred [-9.813081]	</s> [-2.326878]	privilege [-17.248667]	my [-9.775980]	</s> [-2.119247]	racketeer [-17.904753]	hundred [-9.634686]	</s> [-2.394572]	racketeer [-17.775814]	my [-9.581364]	</s> [-2.263423]	shove [-17.079685]	the [-8.545804]	</s> [-1.825666]	shove [-17.148783]	hundred [-9.484019]	</s> [-2.383129]	shove [-17.061010]	a [-9.477464]	</s> [-1.739684]	disembowel [-17.919598]	an [-10.206723]	</s> [-1.885663]	disembowel [-18.022284]	your [-9.030891]	</s> [-1.982753]	disembowel [-17.808073]	hundred [-9.740707]	</s> [-2.187260]	disembowel [-17.627306]	one [-10.022524]	</s> [-1.906847]	decentralize [-16.607767]	an [-9.701038]	</s> [-1.937652]	decentralize [-16.738243]	my [-8.953865]	</s> [-2.077591]	decentralize [-16.649801]	a [-8.845363]	</s> [-1.639833]	dress [-17.194923]	the [-9.341395]	</s> [-1.693316]	dress [-17.328295]	your [-9.441133]	</s> [-2.094636]	dress [-17.362329]	one [-10.457267]	</s> [-2.210162]	dress [-17.445452]	a [-9.815475]	</s> [-1.867576]	intellectualize [-18.095966]	an [-10.481846]	</s> [-1.997358]	intellectualize [-18.233723]	hundred [-9.800856]	</s> [-2.400477]	dehumanize [-18.054733]	a [-9.686125]	</s> [-1.806832]	dehumanize [-17.924332]	one [-10.333038]	</s> [-2.107340]	jeopardize [-17.808052]	hundred [-10.152375]	</s> [-2.480633]	intermarry [-18.707720]	your [-8.185198]	</s> [-2.194853]	intermarry [-18.566483]	a [-9.354635]	</s> [-1.761648]	intermarry [-18.619520]	my [-9.422576]	</s> [-2.146169]	weird [-14.243120]	one [-3.024138]	</s> [-2.184365]	booby [-17.960567]	one [-10.160459]	</s> [-2.189970]	booby [-17.911167]	your [-8.936196]	</s> [-2.217398]	booby [-17.965353]	hundred [-9.542070]	</s> [-2.471084]	undervalue [-18.584270]	one [-10.394366]	</s> [-2.389639]	undervalue [-18.612455]	my [-9.507658]	</s> [-2.422006]	pitchfork [-17.809097]	hundred [-9.722527]	</s> [-2.465058]	pitchfork [-17.813665]	a [-9.183647]	</s> [-1.940028]	ginger [-17.070124]	the [-7.658000]	</s> [-1.857541]	ginger [-17.191315]	an [-9.815168]	</s> [-2.055585]	ginger [-17.304178]	a [-8.517536]	</s> [-1.984922]	crosscheck [-16.589964]	one [-9.704222]	</s> [-2.254551]	power [-17.136158]	one [-10.274752]	</s> [-2.112083]	power [-17.239466]	the [-8.817621]	</s> [-2.043711]	power [-17.347483]	your [-8.878675]	</s> [-2.286003]	folk [-16.637175]	an [-10.057813]	</s> [-2.042488]	mountebank [-17.918398]	my [-10.157790]	</s> [-2.220861]	mountebank [-17.901827]	hundred [-9.900345]	</s> [-2.423492]	mountebank [-17.936340]	a [-9.310998]	</s> [-2.019920]	smooth [-16.138313]	my [-9.606261]	</s> [-2.440238]	blaspheme [-17.285793]	a [-8.928616]	</s> [-2.094568]	blaspheme [-17.390829]	an [-10.186166]	</s> [-2.157903]	blaspheme [-17.320061]	one [-10.380400]	</s> [-2.551751]	demagnetise [-17.649851]	your [-9.208044]	</s> [-2.227323]	demagnetise [-17.920351]	the [-9.106195]	</s> [-2.121091]	come [-17.652302]	one [-9.947442]	</s> [-2.491473]	come [-17.707333]	the [-8.973238]	</s> [-1.865153]	prejudice [-16.663784]	hundred [-9.899014]	</s> [-2.479875]	prejudice [-16.677500]	a [-9.746508]	</s> [-1.972718]	prejudice [-16.646614]	one [-10.254794]	</s> [-2.424236]	brutalize [-17.427734]	one [-10.312597]	</s> [-2.376108]	square [-16.838743]	hundred [-9.898741]	</s> [-2.697593]	square [-16.771456]	a [-9.480849]	</s> [-1.994914]	still [-17.651966]	the [-8.580542]	</s> [-1.995114]	still [-17.643755]	hundred [-9.866202]	</s> [-2.612268]
2024-12-19 08:12:17 | INFO | fairseq_cli.eval_lm | 0 influence [-15.934135]	one [-9.558475]	</s> [-1.701244]	influence [-16.643869]	an [-9.547281]	</s> [-1.768282]	influence [-16.635918]	the [-9.234231]	</s> [-1.443843]	sound [-17.236876]	your [-9.359110]	</s> [-1.919950]	sound [-17.234489]	the [-8.601187]	</s> [-1.674892]	interchange [-16.362495]	one [-9.701847]	</s> [-2.030948]	interchange [-16.469057]	a [-8.851511]	</s> [-1.752795]	interchange [-16.590717]	your [-8.484756]	</s> [-2.063165]	rich [-13.235671]	the [-4.764621]	</s> [-1.754887]	rich [-13.522115]	one [-4.500681]	</s> [-2.016263]	rich [-13.683980]	a [-5.375094]	</s> [-1.580575]	reemphasize [-17.120052]	hundred [-9.260491]	</s> [-2.139105]	commingle [-18.358828]	a [-9.256294]	</s> [-1.523496]	inconvenience [-17.195896]	your [-8.694148]	</s> [-1.827845]	slaughter [-17.864927]	one [-10.052634]	</s> [-1.749785]	slaughter [-18.030645]	hundred [-9.849441]	</s> [-2.218253]	slaughter [-18.231289]	the [-8.694283]	</s> [-1.587050]	slaughter [-18.176262]	an [-9.887588]	</s> [-1.743086]	break [-18.113844]	the [-8.631310]	</s> [-1.614102]	pressurize [-17.686884]	the [-8.987537]	</s> [-1.642571]	pressurize [-17.818731]	your [-9.070046]	</s> [-2.086230]	pressurize [-17.789982]	my [-10.084269]	</s> [-2.158695]	pressurize [-18.023615]	hundred [-10.119704]	</s> [-2.272501]	pressurize [-18.070984]	a [-9.526597]	</s> [-1.754548]	choke [-17.674198]	hundred [-9.679185]	</s> [-2.339712]	choke [-17.574114]	the [-9.039963]	</s> [-1.730232]	choke [-17.557276]	an [-10.524660]	</s> [-1.880180]	distemper [-16.752340]	a [-9.910390]	</s> [-1.559277]	distemper [-16.585367]	the [-8.796497]	</s> [-1.853696]	gallivant [-18.163839]	a [-9.516985]	</s> [-1.549743]	apologize [-18.880276]	my [-10.084630]	</s> [-2.205947]	apologize [-18.954191]	one [-10.665822]	</s> [-2.141358]	apologize [-18.837530]	an [-10.519167]	</s> [-2.055692]	blind [-13.545584]	hundred [-2.874038]	</s> [-2.390222]	wheelbarrow [-17.385807]	an [-10.144102]	</s> [-2.108270]	wheelbarrow [-17.440620]	a [-9.390100]	</s> [-2.020746]	wheelbarrow [-17.406311]	one [-9.767118]	</s> [-2.147055]	headquarter [-17.370253]	an [-10.443094]	</s> [-2.062473]	predetermine [-18.578737]	the [-8.173456]	</s> [-1.875459]	interfere [-18.023848]	a [-8.939003]	</s> [-1.827452]	interfere [-18.046188]	your [-9.330993]	</s> [-2.235176]	dillydally [-17.947933]	an [-10.257565]	</s> [-2.059974]	dillydally [-17.744122]	a [-9.054458]	</s> [-1.678450]	bucket [-17.242868]	your [-8.838806]	</s> [-2.222802]	bucket [-17.371305]	hundred [-9.834002]	</s> [-2.540025]	hero [-17.493370]	an [-10.510584]	</s> [-2.076007]	hero [-17.552427]	a [-9.269180]	</s> [-1.856194]	hero [-17.381662]	one [-9.770372]	</s> [-2.141466]	outbalance [-18.175940]	the [-8.654628]	</s> [-1.998390]	outbalance [-17.980177]	my [-9.398501]	</s> [-2.433576]	outbalance [-17.974792]	your [-8.772552]	</s> [-2.340384]	weasel [-18.623178]	my [-9.894213]	</s> [-2.450663]	weasel [-18.674793]	one [-10.009785]	</s> [-2.535722]	overcharge [-18.252016]	hundred [-9.762357]	</s> [-2.614900]	overcharge [-18.342802]	one [-10.062292]	</s> [-2.375640]	overcharge [-18.365261]	an [-10.553524]	</s> [-2.311859]	misconduct [-17.144901]	an [-10.202769]	</s> [-2.099456]	misconduct [-17.104904]	your [-9.482495]	</s> [-2.116989]	misconduct [-16.934618]	a [-9.745811]	</s> [-1.976211]	spearhead [-17.352818]	one [-9.390852]	</s> [-2.401007]	spearhead [-17.350952]	your [-8.311291]	</s> [-2.370556]	follow [-17.549343]	a [-9.689825]	</s> [-2.100616]	follow [-17.533886]	hundred [-10.070488]	</s> [-2.657997]	vault [-17.898602]	the [-8.842857]	</s> [-1.992393]	vault [-17.748739]	hundred [-9.428965]	</s> [-2.650758]	vault [-17.781818]	one [-9.534604]	</s> [-2.431142]	listen [-17.531889]	the [-7.823190]	</s> [-1.938097]	listen [-17.427710]	an [-10.168280]	</s> [-1.947728]	overspecialize [-17.678915]	your [-8.868576]	</s> [-2.298734]	overspecialize [-17.777603]	hundred [-9.610922]	</s> [-2.425449]	overspecialize [-17.653008]	a [-8.918818]	</s> [-1.843334]	slap [-17.625710]	your [-8.950330]	</s> [-2.322346]	slap [-17.606243]	the [-8.636490]	</s> [-1.836327]	slap [-17.700409]	one [-9.655864]	</s> [-2.375405]	slap [-17.787233]	my [-10.226501]	</s> [-2.549891]	sneeze [-18.609413]	your [-8.908740]	</s> [-2.235674]	sneeze [-18.529921]	the [-8.731724]	</s> [-1.981736]	sneeze [-18.480684]	one [-9.807249]	</s> [-2.200295]	sneeze [-18.471092]	an [-10.033310]	</s> [-2.002220]	bring [-17.440413]	my [-9.817550]	</s> [-2.322134]	bring [-17.532925]	the [-9.100296]	</s> [-2.018126]	run [-15.946989]	my [-8.225056]	</s> [-2.379503]	run [-16.108040]	hundred [-7.635165]	</s> [-2.548108]	run [-16.290016]	your [-6.910107]	</s> [-2.300382]	run [-16.219063]	an [-7.569062]	</s> [-2.183148]	run [-16.076384]	a [-7.636477]	</s> [-1.978353]	circumcise [-18.657610]	an [-10.513293]	</s> [-2.126352]	stand [-17.184996]	a [-9.498417]	</s> [-1.930706]	key [-17.060686]	an [-10.758625]	</s> [-2.194059]	introvert [-16.484983]	the [-9.267741]	</s> [-2.008839]	revitalise [-17.255972]	a [-8.980806]	</s> [-1.968167]	revitalise [-17.033958]	one [-9.344882]	</s> [-2.168566]	revitalise [-16.976328]	your [-8.863360]	</s> [-2.245671]	revitalise [-17.125011]	my [-9.714645]	</s> [-2.555815]	revitalise [-17.081034]	an [-10.270258]	</s> [-2.127615]	bump [-17.994268]	my [-9.850979]	</s> [-2.355302]	rediscover [-17.600887]	one [-9.799015]	</s> [-2.244824]	rediscover [-17.901711]	the [-9.062720]	</s> [-1.854899]	back [-15.602306]	the [-5.935488]	</s> [-2.042513]	back [-15.293576]	one [-6.685348]	</s> [-2.375204]	promenade [-17.816685]	a [-9.475280]	</s> [-1.993166]	promenade [-17.951895]	the [-9.121881]	</s> [-1.949551]	promenade [-18.066799]	hundred [-10.278946]	</s> [-2.654644]	misbehave [-17.498150]	an [-10.494435]	</s> [-2.223211]	misbehave [-17.365149]	the [-8.658912]	</s> [-1.901320]	fall [-18.142250]	an [-10.178799]	</s> [-2.141520]	fall [-18.318651]	the [-8.302368]	</s> [-1.935485]	fall [-18.245869]	hundred [-8.832875]	</s> [-2.396534]	replenish [-16.840973]	my [-9.880061]	</s> [-2.269210]	replenish [-16.855406]	hundred [-10.090695]	</s> [-2.407855]	carry [-18.291245]	the [-9.166101]	</s> [-1.928994]	crash [-18.271431]	hundred [-9.708920]	</s> [-2.516011]	crash [-18.197355]	my [-10.349915]	</s> [-2.290075]	crash [-18.192688]	a [-9.373984]	</s> [-1.876277]	crash [-18.076227]	an [-10.363334]	</s> [-1.976412]	provision [-17.157972]	the [-9.341198]	</s> [-2.054777]	provision [-17.347820]	my [-9.656944]	</s> [-2.511026]	provision [-17.378544]	your [-9.117552]	</s> [-2.268835]	provision [-17.258562]	an [-10.746747]	</s> [-2.222547]	provision [-17.296494]	hundred [-9.669737]	</s> [-2.494841]	track [-16.888922]	hundred [-8.901685]	</s> [-2.587868]	track [-17.118248]	my [-9.793940]	</s> [-2.428483]	splash [-18.219995]	your [-9.082034]	</s> [-2.265074]	splash [-17.973993]	the [-8.931920]	</s> [-1.771345]	intercede [-17.491697]	one [-10.774383]	</s> [-2.251958]	intercede [-17.388281]	hundred [-10.392720]	</s> [-2.533848]	mispronounce [-17.039993]	your [-9.687815]	</s> [-1.922903]	mispronounce [-17.035923]	hundred [-10.058814]	</s> [-2.526784]	mispronounce [-17.171818]	a [-9.686557]	</s> [-1.983686]	fertilize [-18.559673]	your [-9.167419]	</s> [-2.157254]	fertilize [-18.600500]	one [-10.407689]	</s> [-2.240280]	number [-17.756201]	hundred [-9.951849]	</s> [-2.674437]	number [-17.662334]	your [-9.030161]	</s> [-2.252777]	hydroplane [-17.520542]	my [-10.075131]	</s> [-2.402553]	hydroplane [-17.490061]	the [-8.756721]	</s> [-1.938667]	hydroplane [-17.586422]	a [-9.371942]	</s> [-1.764823]	disrespect [-16.540104]	the [-8.374955]	</s> [-1.966748]	disrespect [-16.485067]	a [-9.085595]	</s> [-1.607737]	disrespect [-16.558083]	an [-10.574489]	</s> [-2.054105]	overemphasize [-17.350132]	the [-8.094686]	</s> [-1.943457]	backtrack [-17.626692]	a [-9.360448]	</s> [-1.885238]	backtrack [-17.762560]	hundred [-10.243985]	</s> [-2.597481]	backtrack [-17.753630]	one [-9.898219]	</s> [-2.206119]	prescribe [-17.031080]	my [-9.983933]	</s> [-2.359180]	criticise [-17.278816]	an [-10.007332]	</s> [-2.091058]	criticise [-17.265118]	one [-10.074650]	</s> [-2.316167]	burlesque [-17.713888]	the [-9.164985]	</s> [-2.086660]	burlesque [-17.590967]	one [-10.198462]	</s> [-2.231673]	commercialize [-17.265236]	my [-9.994359]	</s> [-2.396329]	commercialize [-17.494825]	the [-8.828751]	</s> [-2.093254]	rustle [-16.754642]	one [-9.783632]	</s> [-2.109837]	rustle [-16.871387]	hundred [-9.795495]	</s> [-2.452141]	soft [-16.858582]	an [-9.465448]	</s> [-2.238575]	soft [-16.706751]	a [-8.703589]	</s> [-1.779260]	keep [-18.731861]	my [-9.972842]	</s> [-2.275387]	keep [-18.882006]	a [-9.828091]	</s> [-1.978581]	keep [-18.656511]	the [-9.518143]	</s> [-1.929865]	rubber [-16.489790]	an [-10.369316]	</s> [-2.016935]	rubber [-16.377562]	hundred [-10.208076]	</s> [-2.508323]	rubber [-16.249189]	one [-9.904815]	</s> [-2.224700]	glamorize [-17.239704]	my [-9.500466]	</s> [-2.387790]	glamorize [-17.286255]	your [-8.792522]	</s> [-2.189280]	close [-16.735117]	hundred [-9.852060]	</s> [-2.342706]	close [-16.891470]	your [-8.244443]	</s> [-2.276533]	close [-16.885199]	one [-9.669185]	</s> [-2.309332]	stanchion [-17.837219]	hundred [-10.406800]	</s> [-2.622101]	stanchion [-17.773561]	the [-8.925277]	</s> [-1.926614]	get [-17.056177]	my [-10.057196]	</s> [-2.237001]	blackguard [-18.404371]	my [-10.141610]	</s> [-2.201110]	blackguard [-18.461929]	the [-8.796055]	</s> [-1.586101]	blackguard [-18.629190]	your [-9.164598]
2024-12-19 08:12:17 | INFO | fairseq_cli.eval_lm | Evaluated 708 tokens in 0.9s (760.06 tokens/s)
2024-12-19 08:12:17 | INFO | fairseq_cli.eval_lm | Loss (base 2): 13.9141, Perplexity: 15436.58
