2024-12-19 10:18:33 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2024-12-19 10:18:36 | INFO | fairseq_cli.eval_lm | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'checkpoints/grammar41exp2_permutation/8-transformer/checkpoint_best.pt', 'post_process': None, 'quiet': True, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': True, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': None, 'task': {'_name': 'language_modeling', 'data': 'data-bin/grammar41exp2_permutation/correct_8-dataset', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2024-12-19 10:18:36 | INFO | fairseq.tasks.language_modeling | dictionary: 1136 types
2024-12-19 10:18:36 | INFO | fairseq_cli.eval_lm | loading model(s) from checkpoints/grammar41exp2_permutation/8-transformer/checkpoint_best.pt
/workspace/artificial-languages/fairseq/fairseq/checkpoint_utils.py:340: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(f, map_location=torch.device("cpu"))
2024-12-19 10:18:39 | INFO | fairseq_cli.eval_lm | num. model params: 10,038,784
2024-12-19 10:18:39 | INFO | fairseq.data.data_utils | loaded 227 examples from: data-bin/grammar41exp2_permutation/correct_8-dataset/test
2024-12-19 10:18:39 | INFO | fairseq_cli.eval_lm | data-bin/grammar41exp2_permutation/correct_8-dataset test 2 examples
2024-12-19 10:18:39 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-12-19 10:18:39 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True
2024-12-19 10:18:39 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False
2024-12-19 10:18:39 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1
/opt/conda/envs/art/lib/python3.9/site-packages/torch/nn/functional.py:5849: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2024-12-19 10:18:40 | INFO | fairseq_cli.eval_lm | 1 </s> [-1.563829]	constrict [-18.849216]	one [-8.905066]	</s> [-2.364543]	constrict [-19.317015]	the [-9.239868]	</s> [-1.477211]	burlesque [-17.799376]	hundred [-9.164562]	</s> [-1.916003]	burlesque [-18.029869]	one [-10.098843]	</s> [-2.048516]	burlesque [-18.128736]	an [-10.686061]	</s> [-1.892570]	burlesque [-18.153404]	my [-10.155891]	</s> [-1.059855]	fertilize [-17.867601]	the [-8.828889]	</s> [-1.565430]	fertilize [-17.831757]	an [-9.083889]	</s> [-2.234565]	provision [-18.300222]	a [-7.804499]	</s> [-1.670317]	provision [-18.434813]	your [-8.445703]	</s> [-2.027080]	hero [-18.504332]	hundred [-9.143158]	</s> [-1.730150]	hero [-18.430542]	an [-9.541923]	</s> [-2.129533]	inconvenience [-17.986021]	one [-9.630769]	</s> [-1.784008]	circumcise [-18.187639]	a [-8.441113]	</s> [-1.092837]	circumcise [-17.964584]	your [-9.406549]	</s> [-2.109068]	circumcise [-17.974482]	my [-9.318128]	</s> [-1.342419]	circumcise [-18.202789]	hundred [-8.949252]	</s> [-1.861255]	spearhead [-19.029680]	your [-8.258924]	</s> [-2.274702]	spearhead [-18.955122]	hundred [-9.237741]	</s> [-1.825017]	spearhead [-19.064461]	my [-8.821081]	</s> [-1.454609]	dress [-18.074160]	one [-9.285076]	</s> [-2.232368]	dress [-17.861032]	an [-9.705898]	</s> [-2.119443]	dress [-17.964590]	the [-9.112590]	</s> [-1.542611]	promenade [-18.368141]	the [-8.646140]	</s> [-1.660210]	promenade [-18.361822]	an [-9.382537]	</s> [-2.207451]	headquarter [-18.725214]	your [-8.615603]	</s> [-2.107997]	headquarter [-18.760839]	my [-9.072252]	</s> [-0.935694]	headquarter [-18.765276]	an [-9.177637]	</s> [-2.418927]	listen [-18.138672]	my [-8.778824]	</s> [-1.622539]	listen [-18.341370]	hundred [-9.333500]	</s> [-1.694956]	outbalance [-19.084547]	one [-10.189725]	</s> [-2.082253]	outbalance [-19.017864]	the [-9.888749]	</s> [-1.387439]	outbalance [-18.826712]	a [-8.369042]	</s> [-1.676074]	outbalance [-19.003391]	your [-9.095339]	</s> [-2.357774]	gallivant [-16.625368]	an [-9.455683]	</s> [-2.312462]	reemphasize [-17.911697]	the [-8.918581]	</s> [-1.556625]	pressurize [-18.332104]	one [-8.857543]	</s> [-2.104178]	pressurize [-18.309649]	an [-9.534113]	</s> [-2.255950]	pressurize [-18.342358]	your [-7.979150]	</s> [-2.357831]	pressurize [-18.375254]	hundred [-8.450857]	</s> [-1.965438]	prescribe [-17.976271]	one [-9.375711]	</s> [-2.020270]	prescribe [-17.772163]	your [-8.798387]	</s> [-1.794983]	key [-17.695894]	one [-9.295066]	</s> [-1.677578]	key [-17.683519]	my [-8.706952]	</s> [-1.538365]	interchange [-18.333908]	the [-10.143385]	</s> [-1.492052]	interchange [-18.321573]	my [-9.607083]	</s> [-1.118703]	misconduct [-18.130947]	the [-9.854262]	</s> [-1.279914]	misconduct [-18.096014]	hundred [-9.540729]	</s> [-1.657544]	misconduct [-17.936125]	an [-9.982231]	</s> [-2.235317]	bucket [-18.286743]	one [-9.073540]	</s> [-2.161457]	bucket [-18.365475]	your [-8.263211]	</s> [-2.138757]	bucket [-18.386414]	hundred [-8.774218]	</s> [-1.638506]	rustle [-18.770081]	an [-9.791915]	</s> [-2.033111]	rustle [-18.788393]	your [-9.292696]	</s> [-1.874402]	backtrack [-18.044607]	my [-8.702833]	</s> [-1.446179]	backtrack [-18.116161]	one [-8.643355]	</s> [-2.234623]
2024-12-19 10:18:40 | INFO | fairseq_cli.eval_lm | 0 crosscheck [-17.449789]	hundred [-7.643074]	</s> [-1.906397]	crosscheck [-18.958609]	one [-8.417604]	</s> [-1.910040]	decentralize [-18.667051]	hundred [-8.704288]	</s> [-1.804095]	decentralize [-18.839020]	my [-9.166309]	</s> [-1.300234]	decentralize [-18.933933]	a [-8.445613]	</s> [-1.090596]	keep [-17.053949]	one [-9.883538]	</s> [-1.826518]	keep [-17.056665]	an [-10.295525]	</s> [-2.301645]	keep [-17.014183]	your [-8.965158]	</s> [-2.370076]	soft [-16.056774]	the [-8.732242]	</s> [-1.961843]	soft [-15.911527]	hundred [-8.895018]	</s> [-1.913496]	pitchfork [-17.467411]	my [-9.773838]	</s> [-1.149427]	pitchfork [-17.370289]	the [-9.566456]	</s> [-1.802253]	pitchfork [-17.293114]	one [-9.624162]	</s> [-2.004463]	pitchfork [-17.423660]	a [-8.557965]	</s> [-1.194079]	bump [-18.806534]	hundred [-9.871322]	</s> [-1.957631]	bump [-18.694563]	a [-8.808405]	</s> [-1.682810]	give [-17.456823]	an [-8.569790]	</s> [-2.318339]	give [-17.581741]	your [-7.225902]	</s> [-2.388348]	give [-17.368711]	a [-7.295418]	</s> [-1.810860]	sneeze [-18.384647]	a [-8.351640]	</s> [-1.679292]	sneeze [-18.475670]	one [-9.222449]	</s> [-2.259513]	distemper [-17.772318]	hundred [-9.398091]	</s> [-1.913325]	disrespect [-18.284510]	an [-9.834837]	</s> [-2.233830]	disrespect [-18.504745]	your [-8.941523]	</s> [-2.295082]	disrespect [-18.528576]	a [-8.252662]	</s> [-1.601418]	dillydally [-18.127708]	hundred [-9.145688]	</s> [-1.969690]	dillydally [-18.062666]	the [-9.204772]	</s> [-1.489861]	dillydally [-18.161419]	a [-8.341442]	</s> [-1.699904]	still [-17.885197]	one [-9.219811]	</s> [-2.526128]	square [-14.819838]	one [-8.983610]	</s> [-2.133686]	square [-14.955189]	an [-9.457520]	</s> [-2.398900]	choke [-19.076376]	an [-10.011103]	</s> [-2.258985]	choke [-18.860344]	the [-9.033801]	</s> [-1.898368]	choke [-18.832083]	my [-9.457520]	</s> [-1.922589]	carry [-17.823633]	hundred [-8.657536]	</s> [-1.980707]	carry [-17.731125]	a [-7.740324]	</s> [-1.902523]	carry [-17.795816]	one [-8.741014]	</s> [-2.195197]	carry [-17.867905]	the [-8.930668]	</s> [-1.640574]	jeopardize [-19.315042]	an [-9.662213]	</s> [-2.339569]	jeopardize [-19.294954]	one [-9.366995]	</s> [-2.275345]	jeopardize [-19.421566]	your [-9.218801]	</s> [-2.247895]	jeopardize [-19.263153]	my [-9.376675]	</s> [-1.312321]	blackguard [-17.454985]	my [-9.187945]	</s> [-0.904152]	blackguard [-17.480026]	a [-7.999939]	</s> [-1.553146]	brutalize [-19.151741]	an [-9.940874]	</s> [-2.424741]	brutalize [-19.138443]	my [-9.949695]	</s> [-1.205958]	brutalize [-19.265394]	your [-9.206223]	</s> [-2.102930]	introvert [-18.173666]	a [-8.174119]	</s> [-0.980525]	introvert [-18.181265]	one [-9.405230]	</s> [-2.202395]	introvert [-18.088591]	hundred [-8.891738]	</s> [-2.012701]	prejudice [-18.616869]	hundred [-9.738448]	</s> [-1.895496]	undervalue [-18.655125]	an [-9.629979]	</s> [-2.112253]	undervalue [-18.605719]	the [-9.025691]	</s> [-1.362451]	undervalue [-18.639847]	your [-8.582460]	</s> [-2.013634]	overspecialize [-18.760536]	hundred [-9.037236]	</s> [-1.792048]	slaughter [-18.186079]	the [-9.098105]	</s> [-1.803278]	slaughter [-18.083080]	your [-8.743776]	</s> [-2.077948]	back [-15.675747]	one [-7.475097]	</s> [-1.734216]	back [-15.312981]	my [-6.475608]	</s> [-1.347454]	break [-17.794327]	my [-8.777075]	</s> [-1.113662]	break [-17.844872]	your [-8.842356]	</s> [-2.135190]	interfere [-17.892822]	my [-8.854591]	</s> [-1.540238]	get [-17.432257]	an [-10.156446]	</s> [-2.253736]	get [-17.322403]	hundred [-9.080174]	</s> [-2.118272]	get [-17.473131]	one [-9.450574]	</s> [-2.325737]	criticise [-17.429741]	your [-8.772487]	</s> [-2.177261]	criticise [-17.257788]	the [-9.261435]	</s> [-1.118539]	crash [-17.311684]	your [-8.673767]	</s> [-1.680715]	crash [-17.453123]	my [-8.555776]	</s> [-1.306515]	number [-17.407038]	your [-8.723756]	</s> [-2.000234]	number [-17.256714]	a [-8.076698]	</s> [-1.338439]	number [-17.205256]	the [-9.419891]	</s> [-1.483562]	blind [-14.358405]	one [-3.917827]	</s> [-1.885253]	blind [-14.495659]	an [-4.366823]	</s> [-2.251675]	blind [-14.746377]	the [-4.062063]	</s> [-1.641116]	disembowel [-18.032724]	a [-8.011487]	</s> [-0.748491]	disembowel [-17.923954]	hundred [-8.568966]	</s> [-1.398906]	slap [-18.233301]	hundred [-8.666006]	</s> [-1.541740]	sweet [-15.171143]	your [-3.546134]	</s> [-2.111365]	sweet [-15.305342]	a [-3.247181]	</s> [-1.657456]	intermarry [-18.008783]	my [-8.714707]	</s> [-1.405394]	misbehave [-17.680794]	hundred [-8.360381]	</s> [-1.708853]	misbehave [-17.706518]	my [-8.806236]	</s> [-0.654785]	splash [-18.536850]	an [-10.103459]	</s> [-1.981720]	splash [-18.442141]	the [-9.274494]	</s> [-1.369047]	splash [-18.392370]	a [-8.629156]	</s> [-0.989009]	mispronounce [-17.912148]	a [-8.252675]	</s> [-1.175593]	mispronounce [-17.814445]	one [-9.076998]	</s> [-1.802763]	folk [-17.680649]	your [-9.108090]	</s> [-2.176461]	folk [-17.629370]	an [-9.759932]	</s> [-2.347046]	folk [-17.746376]	the [-9.324352]	</s> [-1.745403]	stanchion [-19.287481]	an [-9.463713]	</s> [-2.214432]	stanchion [-19.221579]	hundred [-8.515648]	</s> [-1.735733]	stanchion [-19.208447]	your [-8.991140]	</s> [-2.161128]	secularize [-17.915546]	a [-8.114162]	</s> [-1.298078]	revitalise [-17.598816]	one [-8.973048]	</s> [-2.032019]	revitalise [-17.604191]	the [-9.001228]	</s> [-1.113440]	shove [-16.917204]	one [-9.340221]	</s> [-1.698112]	shove [-16.839123]	a [-7.694446]	</s> [-1.607223]	shove [-16.734066]	your [-8.631943]	</s> [-2.048602]	sound [-17.358616]	one [-9.645922]	</s> [-2.053599]	sound [-17.486788]	your [-8.557613]	</s> [-2.193442]	booby [-18.480696]	hundred [-9.179599]	</s> [-1.965005]	booby [-18.593340]	your [-9.304609]	</s> [-2.341763]	booby [-18.452475]	my [-8.997126]	</s> [-1.544839]	overemphasize [-18.107134]	a [-8.111456]	</s> [-1.354776]	overemphasize [-18.230106]	your [-8.778100]	</s> [-2.215886]	blaspheme [-17.364624]	my [-9.270802]	</s> [-1.726068]	blaspheme [-17.128351]	a [-8.335147]	</s> [-1.676782]	blaspheme [-17.056959]	an [-10.058602]	</s> [-2.098016]	blaspheme [-17.176254]	hundred [-9.433007]	</s> [-1.846242]	privilege [-17.414310]	my [-8.705604]	</s> [-1.796111]	privilege [-17.312866]	hundred [-8.655410]	</s> [-1.673000]	bring [-18.836170]	the [-8.989490]	</s> [-1.309431]	bring [-18.808687]	my [-9.056759]	</s> [-1.051249]	rediscover [-16.367659]	the [-10.310084]	</s> [-1.519079]	follow [-17.663568]	the [-8.863985]	</s> [-1.632568]	follow [-17.677238]	hundred [-8.686709]	</s> [-1.733695]	mountebank [-17.811644]	your [-9.063489]	</s> [-2.097847]	mountebank [-17.748787]	hundred [-8.721058]	</s> [-1.871065]	mountebank [-17.943773]	a [-8.038363]	</s> [-1.533711]	predetermine [-18.990341]	one [-9.514429]	</s> [-2.269621]	predetermine [-18.745121]	an [-9.422092]	</s> [-2.472199]	medium [-13.159216]	a [-5.444005]	</s> [-1.684433]	buttonhole [-17.165871]	an [-9.488818]	</s> [-2.145053]	run [-16.087690]	one [-8.079922]	</s> [-1.925803]	run [-16.006821]	an [-8.871944]	</s> [-2.180720]	hydroplane [-18.909737]	my [-9.733157]	</s> [-1.274369]	hydroplane [-18.983259]	the [-9.696528]	</s> [-1.941934]	hydroplane [-19.014654]	one [-9.946898]	</s> [-2.140781]	rich [-13.962549]	a [-5.016663]	</s> [-1.515154]	commercialize [-16.502144]	a [-8.004361]	</s> [-1.553085]	fall [-18.206493]	one [-9.200743]	</s> [-2.123113]	fall [-18.134287]	the [-8.922358]	</s> [-1.746149]	fall [-18.159609]	your [-8.848223]	</s> [-2.126308]	come [-18.602743]	my [-8.641691]	</s> [-1.460717]	come [-18.568066]	one [-9.007277]	</s> [-2.292649]	commingle [-18.265221]	your [-9.501555]	</s> [-2.381139]	dehumanize [-17.070007]	my [-9.280068]	</s> [-1.703042]	dehumanize [-16.918335]	your [-9.056958]	</s> [-2.307712]	dehumanize [-16.948036]	hundred [-8.709904]	</s> [-1.707895]	smooth [-17.225840]	the [-9.133243]	</s> [-1.665337]	smooth [-17.279881]	your [-8.647480]	</s> [-2.189167]	power [-18.123938]	my [-9.470743]	</s> [-1.471779]	power [-18.252775]	one [-9.895838]	</s> [-2.342378]	power [-18.118923]	your [-9.043544]	</s> [-2.463852]	wheelbarrow [-17.130194]	one [-9.326257]	</s> [-2.195002]	wheelbarrow [-17.085329]	your [-8.538044]	</s> [-2.430045]	vault [-17.493370]	one [-9.795378]	</s> [-2.311315]	vault [-17.683519]	hundred [-8.986640]	</s> [-2.089406]	close [-17.178736]	hundred [-8.789357]	</s> [-1.795965]	close [-17.420326]	an [-9.549317]	</s> [-2.357303]	intercede [-17.414053]	hundred [-8.227709]	</s> [-2.094207]	intercede [-17.495815]	an [-9.460462]	</s> [-2.292773]	intercede [-17.414494]	your [-8.466917]	</s> [-2.346686]	ginger [-17.977375]	one [-10.190372]	</s> [-2.141757]	ginger [-17.750038]	my [-9.666011]	</s> [-1.450860]	glamorize [-17.693937]	a [-8.961929]	</s> [-1.424621]	glamorize [-17.805359]	one [-10.402548]	</s> [-2.365147]	glamorize [-17.716221]	an [-10.596828]	</s> [-2.304054]	replenish [-17.368719]	one [-9.666484]	</s> [-2.308285]	replenish [-17.387644]	a [-8.673941]	</s> [-1.779933]	influence [-17.279669]	your [-8.730238]	</s> [-2.102153]	racketeer [-17.783298]	an [-9.814005]	</s> [-2.225805]	racketeer [-17.860970]	your [-8.822960]	</s> [-2.271976]	racketeer [-17.860857]	a [-7.809441]	</s> [-1.803014]	overcharge [-17.439629]	your [-9.003325]	</s> [-2.209533]	overcharge [-17.392025]	one [-9.668684]	</s> [-2.075557]	overcharge [-17.394022]	hundred [-8.868654]	</s> [-1.987653]	track [-18.691023]	one [-10.483340]	</s> [-1.576764]	track [-18.768806]	the [-9.583646]
2024-12-19 10:18:40 | INFO | fairseq_cli.eval_lm | Evaluated 681 tokens in 1.0s (671.51 tokens/s)
2024-12-19 10:18:40 | INFO | fairseq_cli.eval_lm | Loss (base 2): 13.7517, Perplexity: 13793.66
