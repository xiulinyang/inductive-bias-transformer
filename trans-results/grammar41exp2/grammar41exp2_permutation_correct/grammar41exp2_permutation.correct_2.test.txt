2024-12-19 07:38:57 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2024-12-19 07:38:59 | INFO | fairseq_cli.eval_lm | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'checkpoints/grammar41exp2_permutation/2-transformer/checkpoint_best.pt', 'post_process': None, 'quiet': True, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': True, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': None, 'task': {'_name': 'language_modeling', 'data': 'data-bin/grammar41exp2_permutation/correct_2-dataset', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2024-12-19 07:38:59 | INFO | fairseq.tasks.language_modeling | dictionary: 1136 types
2024-12-19 07:38:59 | INFO | fairseq_cli.eval_lm | loading model(s) from checkpoints/grammar41exp2_permutation/2-transformer/checkpoint_best.pt
/workspace/artificial-languages/fairseq/fairseq/checkpoint_utils.py:340: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(f, map_location=torch.device("cpu"))
2024-12-19 07:39:02 | INFO | fairseq_cli.eval_lm | num. model params: 10,038,784
2024-12-19 07:39:02 | INFO | fairseq.data.data_utils | loaded 222 examples from: data-bin/grammar41exp2_permutation/correct_2-dataset/test
2024-12-19 07:39:02 | INFO | fairseq_cli.eval_lm | data-bin/grammar41exp2_permutation/correct_2-dataset test 2 examples
2024-12-19 07:39:02 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-12-19 07:39:02 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True
2024-12-19 07:39:02 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False
2024-12-19 07:39:02 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1
/opt/conda/envs/art/lib/python3.9/site-packages/torch/nn/functional.py:5849: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2024-12-19 07:39:03 | INFO | fairseq_cli.eval_lm | 1 </s> [-1.603948]	misbehave [-15.896359]	my [-5.703024]	</s> [-2.460398]	run [-14.754941]	your [-8.272468]	</s> [-2.010642]	run [-14.884949]	an [-8.457517]	</s> [-2.108045]	run [-14.611915]	hundred [-8.253070]	</s> [-1.716364]	run [-14.377371]	a [-9.450132]	</s> [-2.417135]	blind [-11.992336]	the [-4.616443]	</s> [-1.883602]	blind [-12.191116]	a [-3.664555]	</s> [-2.424248]	intermarry [-16.850641]	one [-9.379870]	</s> [-2.068546]	intermarry [-16.674164]	my [-9.119248]	</s> [-2.166895]	criticise [-17.862717]	one [-9.154168]	</s> [-1.919482]	criticise [-17.707705]	an [-10.464145]	</s> [-1.840901]	criticise [-17.614023]	your [-9.722702]	</s> [-1.681975]	criticise [-17.575617]	the [-9.972661]	</s> [-1.786852]	stanchion [-16.169958]	a [-9.840451]	</s> [-2.234642]	stanchion [-16.031872]	an [-10.111971]	</s> [-1.795552]	disembowel [-16.429707]	an [-9.465470]	</s> [-2.001351]	disembowel [-16.583662]	hundred [-9.015458]	</s> [-1.771449]	get [-16.299908]	hundred [-9.200893]	</s> [-1.762046]	get [-16.198074]	an [-9.815910]	</s> [-1.866839]	headquarter [-16.212536]	your [-9.591421]	</s> [-1.608883]	headquarter [-16.169594]	my [-9.239018]	</s> [-2.015891]	headquarter [-16.060879]	one [-9.250622]	</s> [-1.848698]	outbalance [-15.337978]	the [-9.950606]	</s> [-1.931311]	brutalize [-16.438580]	a [-9.739546]	</s> [-2.349831]	brutalize [-16.570572]	the [-9.654855]	</s> [-1.769182]	still [-16.542429]	an [-9.999117]	</s> [-1.880330]	still [-16.681936]	my [-9.333257]	</s> [-1.960581]	still [-16.638659]	a [-9.945699]	</s> [-2.287876]	crash [-15.401758]	my [-8.950644]	</s> [-1.985842]	crash [-15.567578]	a [-10.127086]	</s> [-2.310820]	interchange [-15.771973]	a [-10.256897]	</s> [-2.253523]	interchange [-15.736522]	my [-9.100006]	</s> [-2.029062]	overcharge [-16.307295]	a [-9.873494]	</s> [-2.392346]	overcharge [-16.465919]	my [-9.639819]	</s> [-2.093138]	come [-17.051197]	my [-9.054731]	</s> [-2.043550]	listen [-15.283265]	hundred [-9.743762]	</s> [-1.567660]	weasel [-16.243792]	your [-9.126572]	</s> [-1.715336]	weasel [-16.226963]	the [-9.201252]	</s> [-1.829996]	bring [-16.838667]	hundred [-9.245559]	</s> [-1.671055]	bring [-17.013474]	one [-8.594813]	</s> [-1.864973]	backtrack [-16.611103]	an [-10.217875]	</s> [-1.895679]	backtrack [-16.560972]	your [-9.851626]	</s> [-1.286347]	backtrack [-16.311689]	a [-10.113002]	</s> [-1.883833]	carry [-16.353119]	hundred [-9.859512]	</s> [-1.467613]	carry [-16.563433]	an [-10.512527]	</s> [-1.939657]	decentralize [-16.357876]	hundred [-9.611285]	</s> [-1.487443]	circumcise [-15.566275]	one [-8.987587]	</s> [-1.606517]	circumcise [-15.450820]	the [-9.501645]	</s> [-1.750451]	inconvenience [-15.818991]	one [-9.035357]	</s> [-1.802012]	inconvenience [-15.730671]	the [-9.515093]	</s> [-1.890563]	inconvenience [-16.121832]	my [-9.160636]	</s> [-2.095358]
2024-12-19 07:39:03 | INFO | fairseq_cli.eval_lm | 0 prescribe [-15.105389]	one [-5.979556]	</s> [-1.572549]	prescribe [-16.691463]	the [-8.722793]	</s> [-1.641639]	promenade [-16.205402]	one [-9.023010]	</s> [-1.333021]	promenade [-16.264860]	an [-10.280416]	</s> [-1.955565]	promenade [-15.996250]	your [-9.494972]	</s> [-1.470914]	promenade [-16.110596]	a [-9.671658]	</s> [-2.193807]	pitchfork [-17.289528]	hundred [-9.634317]	</s> [-1.128666]	pitchfork [-17.311310]	the [-9.480250]	</s> [-1.830283]	slaughter [-16.080391]	hundred [-9.369282]	</s> [-1.404995]	slaughter [-16.108639]	your [-9.426869]	</s> [-1.732309]	choke [-17.038416]	hundred [-9.919679]	</s> [-1.011491]	choke [-17.001501]	one [-9.433998]	</s> [-1.460659]	follow [-16.215008]	hundred [-9.730920]	</s> [-1.044130]	shove [-16.425348]	an [-10.235861]	</s> [-1.738955]	shove [-16.433439]	one [-9.184599]	</s> [-1.288176]	shove [-16.392530]	hundred [-9.993915]	</s> [-1.168403]	track [-17.065796]	a [-9.273273]	</s> [-2.245687]	influence [-16.645660]	the [-9.147227]	</s> [-1.747297]	apologize [-16.282095]	one [-8.887868]	</s> [-1.523654]	apologize [-16.436211]	your [-9.591772]	</s> [-1.352565]	apologize [-16.563272]	hundred [-9.663328]	</s> [-1.285011]	ginger [-15.348247]	a [-9.849932]	</s> [-2.164860]	fall [-16.092922]	your [-9.569647]	</s> [-1.578841]	fall [-16.271046]	a [-9.648459]	</s> [-2.189423]	booby [-16.026550]	an [-10.671246]	</s> [-1.555862]	booby [-15.934546]	your [-10.222333]	</s> [-1.403122]	booby [-16.043159]	a [-10.383372]	</s> [-2.156301]	booby [-16.112236]	one [-9.521708]	</s> [-1.542712]	privilege [-16.256027]	one [-9.347632]	</s> [-1.671269]	privilege [-16.371601]	my [-9.398795]	</s> [-1.754702]	privilege [-16.253698]	the [-9.316333]	</s> [-1.657623]	stand [-15.577320]	your [-9.374086]	</s> [-1.559443]	bump [-16.936052]	one [-8.958809]	</s> [-1.812155]	bump [-16.935711]	hundred [-9.646637]	</s> [-1.611524]	bump [-17.138773]	an [-9.998657]	</s> [-1.869421]	bump [-16.944052]	your [-9.570354]	</s> [-1.621285]	rediscover [-15.832815]	my [-9.401795]	</s> [-1.940247]	rediscover [-15.789628]	hundred [-9.788485]	</s> [-1.379245]	give [-13.785971]	hundred [-8.672774]	</s> [-1.418249]	give [-13.960470]	an [-9.041241]	</s> [-1.889157]	give [-14.040029]	my [-8.245495]	</s> [-1.894019]	sneeze [-15.528565]	my [-8.566830]	</s> [-1.711907]	sneeze [-15.342065]	a [-9.786159]	</s> [-1.795233]	sneeze [-15.270152]	your [-9.184834]	</s> [-1.238914]	sneeze [-15.441670]	one [-8.733360]	</s> [-1.678466]	blackguard [-15.969073]	your [-9.955958]	</s> [-1.531903]	blackguard [-16.075159]	hundred [-10.025601]	</s> [-1.197027]	wheelbarrow [-15.118494]	my [-8.968092]	</s> [-1.744709]	prejudice [-15.679875]	your [-9.521562]	</s> [-1.572073]	intercede [-15.144864]	a [-9.389727]	</s> [-2.192762]	intercede [-15.462886]	the [-9.364195]	</s> [-1.784809]	fertilize [-15.981617]	my [-9.293045]	</s> [-1.910038]	fertilize [-15.900229]	an [-10.686463]	</s> [-1.802262]	fertilize [-15.953184]	a [-10.271560]	</s> [-2.122482]	hydroplane [-16.654991]	your [-9.889276]	</s> [-1.593342]	hydroplane [-16.776190]	the [-9.642922]	</s> [-1.812047]	hydroplane [-16.601328]	hundred [-9.792233]	</s> [-1.324491]	revitalise [-16.753178]	an [-10.395948]	</s> [-1.644442]	rustle [-16.424574]	the [-9.287645]	</s> [-1.676459]	rustle [-16.415855]	hundred [-9.396125]	</s> [-1.493628]	burlesque [-16.455095]	your [-9.812879]	</s> [-1.684278]	burlesque [-16.441702]	a [-9.841710]	</s> [-2.276576]	burlesque [-16.304190]	one [-8.908753]	</s> [-1.446397]	dillydally [-15.867092]	your [-9.741362]	</s> [-1.716526]	dillydally [-16.139729]	my [-8.659737]	</s> [-2.053480]	dillydally [-16.381947]	an [-9.983029]	</s> [-1.908420]	introvert [-16.330225]	the [-9.023408]	</s> [-1.717828]	introvert [-16.340832]	a [-10.241556]	</s> [-2.139681]	introvert [-16.411863]	an [-10.117344]	</s> [-1.971999]	bucket [-16.316299]	your [-9.857299]	</s> [-1.840432]	dress [-15.619952]	one [-9.336046]	</s> [-1.791907]	folk [-16.525043]	the [-9.558656]	</s> [-1.809039]	folk [-16.454327]	one [-8.888411]	</s> [-1.670657]	provision [-16.017441]	the [-9.216083]	</s> [-1.875946]	glamorize [-15.699231]	one [-8.339642]	</s> [-1.991537]	glamorize [-15.716734]	hundred [-9.399911]	</s> [-1.306186]	glamorize [-15.660165]	your [-9.468819]	</s> [-1.614641]	rich [-11.686983]	a [-3.798241]	</s> [-2.098765]	undervalue [-17.068207]	a [-9.660028]	</s> [-2.102026]	undervalue [-17.078951]	hundred [-9.934575]	</s> [-1.575367]	square [-13.629563]	the [-9.207460]	</s> [-1.686463]	square [-13.874894]	one [-8.862734]	</s> [-1.615909]	square [-13.872132]	my [-8.674418]	</s> [-1.784664]	power [-16.489527]	the [-9.074092]	</s> [-1.645154]	pressurize [-16.334120]	the [-9.315647]	</s> [-1.760626]	pressurize [-16.168613]	my [-9.346297]	</s> [-1.996824]	medium [-10.776313]	an [-2.869109]	</s> [-1.939624]	hero [-15.973592]	a [-9.898618]	</s> [-2.124725]	hero [-15.936130]	one [-8.742372]	</s> [-1.657535]	racketeer [-15.700075]	hundred [-9.253381]	</s> [-1.505663]	racketeer [-15.732628]	your [-9.710561]	</s> [-1.661870]	racketeer [-15.602620]	one [-9.199947]	</s> [-1.631929]	number [-16.559469]	a [-9.814752]	</s> [-2.214988]	number [-16.534424]	an [-10.426253]	</s> [-1.975313]	dehumanize [-15.812190]	your [-9.961072]	</s> [-1.573024]	dehumanize [-15.655040]	an [-10.265465]	</s> [-1.945682]	dehumanize [-15.670702]	hundred [-10.230907]	</s> [-1.474008]	dehumanize [-16.133518]	a [-10.339799]	</s> [-2.180166]	intellectualize [-16.142319]	an [-10.591229]	</s> [-1.796582]	intellectualize [-16.136658]	my [-9.828444]	</s> [-1.915679]	blaspheme [-16.133423]	my [-9.375684]	</s> [-2.017443]	blaspheme [-16.279299]	your [-10.151011]	</s> [-1.665391]	blaspheme [-16.521910]	a [-10.238480]	</s> [-2.236662]	key [-17.083338]	a [-9.843769]	</s> [-2.256699]	mountebank [-16.358999]	one [-8.810969]	</s> [-1.784528]	mountebank [-16.342119]	my [-9.314070]	</s> [-1.958753]	smooth [-16.565018]	one [-9.202544]	</s> [-1.832723]	smooth [-16.771971]	my [-9.132478]	</s> [-2.011942]	spearhead [-16.974241]	your [-9.675212]	</s> [-1.623041]	spearhead [-17.070177]	a [-10.056126]	</s> [-2.147356]	spearhead [-17.264904]	my [-9.500019]	</s> [-1.895374]	spearhead [-17.169886]	one [-8.873045]	</s> [-1.752628]	mispronounce [-15.255210]	an [-10.495009]	</s> [-1.856750]	demagnetise [-16.716280]	your [-9.591352]	</s> [-1.649912]	demagnetise [-16.844557]	a [-10.140775]	</s> [-2.226457]	demagnetise [-16.691114]	one [-9.040221]	</s> [-1.798931]	demagnetise [-16.996143]	hundred [-9.614324]	</s> [-1.837503]	break [-16.210051]	hundred [-9.720888]	</s> [-1.736100]	break [-15.996301]	a [-9.880392]	</s> [-2.293933]	break [-15.953972]	my [-9.141747]	</s> [-2.028238]	break [-16.293167]	one [-8.947656]	</s> [-2.018844]	buttonhole [-15.346433]	one [-8.841325]	</s> [-1.880391]	buttonhole [-15.071755]	hundred [-9.097599]	</s> [-1.765710]	buttonhole [-15.006406]	my [-8.938272]	</s> [-1.942366]	constrict [-16.051302]	the [-9.360766]	</s> [-1.772208]	constrict [-16.271652]	a [-9.998093]	</s> [-2.101302]	reemphasize [-16.115208]	a [-9.994424]	</s> [-2.080795]	gallivant [-16.018381]	one [-9.231971]	</s> [-1.225533]	replenish [-16.090359]	hundred [-9.371192]	</s> [-1.555903]	replenish [-16.047342]	one [-8.813821]	</s> [-1.666744]	replenish [-16.196505]	an [-10.023457]	</s> [-1.961970]	crosscheck [-16.542965]	one [-9.121055]	</s> [-1.741583]	crosscheck [-16.226658]	an [-10.244439]	</s> [-1.888493]	commingle [-15.644595]	your [-9.441041]	</s> [-1.901030]	commingle [-15.637540]	hundred [-9.594114]	</s> [-1.637821]	commingle [-15.906276]	my [-9.005572]	</s> [-1.881803]	secularize [-16.344078]	a [-9.926670]	</s> [-2.279878]	rubber [-16.168407]	the [-8.999418]	</s> [-1.917539]	rubber [-16.278358]	my [-8.697674]	</s> [-1.941972]	sweet [-11.332367]	a [-3.404366]	</s> [-2.240165]	overemphasize [-16.883343]	an [-9.711444]	</s> [-1.873624]	overemphasize [-16.796227]	your [-9.552921]	</s> [-1.922994]	commercialize [-15.462942]	my [-8.941207]	</s> [-2.060976]	commercialize [-15.502312]	an [-9.825044]	</s> [-1.903603]	commercialize [-15.725772]	hundred [-9.358915]	</s> [-1.789753]	splash [-16.294420]	an [-10.478994]	</s> [-2.027481]	splash [-16.272190]	my [-9.119788]	</s> [-1.983160]	splash [-16.105240]	one [-8.863591]	</s> [-1.883058]	soft [-15.244603]	your [-9.632119]	</s> [-1.974076]	soft [-15.296445]	my [-9.123309]	</s> [-2.022713]	soft [-15.048600]	one [-9.185822]	</s> [-1.660246]	back [-13.524645]	a [-6.742229]	</s> [-2.218743]	back [-13.084278]	an [-5.613001]	</s> [-2.064549]	back [-13.091793]	my [-5.837288]	</s> [-1.974669]	back [-13.586597]	hundred [-6.639844]	</s> [-1.688929]	distemper [-17.380177]	hundred [-9.568448]	</s> [-1.762944]	distemper [-16.838449]	one [-8.784796]	</s> [-1.771980]	misconduct [-16.818523]	one [-9.448712]	</s> [-1.752779]	misconduct [-16.762611]	the [-9.797449]	</s> [-1.738326]	misconduct [-16.838055]	an [-10.573244]	</s> [-1.893716]	misconduct [-16.891069]	a [-10.316087]	</s> [-2.327218]	keep [-16.053688]	the [-9.788424]	</s> [-1.889589]	keep [-16.065390]	my [-9.046059]	</s> [-1.955048]	keep [-15.592735]	hundred [-9.576550]	</s> [-1.647306]	keep [-15.914969]	an [-10.617492]	</s> [-2.056688]	sound [-16.338739]	one [-9.156828]	</s> [-1.913910]	sound [-16.240187]	an [-10.345331]	</s> [-2.034136]	sound [-16.325184]	the [-9.680009]	</s> [-1.772522]	sound [-16.244736]	my [-9.173137]	</s> [-1.868585]	misbehave [-15.071402]	a [-9.639801]	</s> [-2.210127]	misbehave [-15.208064]	hundred [-8.979342]
2024-12-19 07:39:03 | INFO | fairseq_cli.eval_lm | Evaluated 666 tokens in 0.8s (817.93 tokens/s)
2024-12-19 07:39:03 | INFO | fairseq_cli.eval_lm | Loss (base 2): 13.0341, Perplexity: 8388.07
