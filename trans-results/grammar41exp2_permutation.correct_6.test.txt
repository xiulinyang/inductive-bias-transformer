2024-12-19 09:29:47 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2024-12-19 09:29:49 | INFO | fairseq_cli.eval_lm | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'checkpoints/grammar41exp2_permutation/6-transformer/checkpoint_best.pt', 'post_process': None, 'quiet': True, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': True, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': None, 'task': {'_name': 'language_modeling', 'data': 'data-bin/grammar41exp2_permutation/correct_6-dataset', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2024-12-19 09:29:49 | INFO | fairseq.tasks.language_modeling | dictionary: 1136 types
2024-12-19 09:29:49 | INFO | fairseq_cli.eval_lm | loading model(s) from checkpoints/grammar41exp2_permutation/6-transformer/checkpoint_best.pt
/workspace/artificial-languages/fairseq/fairseq/checkpoint_utils.py:340: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(f, map_location=torch.device("cpu"))
2024-12-19 09:29:52 | INFO | fairseq_cli.eval_lm | num. model params: 10,038,784
2024-12-19 09:29:52 | INFO | fairseq.data.data_utils | loaded 247 examples from: data-bin/grammar41exp2_permutation/correct_6-dataset/test
2024-12-19 09:29:52 | INFO | fairseq_cli.eval_lm | data-bin/grammar41exp2_permutation/correct_6-dataset test 2 examples
2024-12-19 09:29:52 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-12-19 09:29:52 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True
2024-12-19 09:29:52 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False
2024-12-19 09:29:52 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1
/opt/conda/envs/art/lib/python3.9/site-packages/torch/nn/functional.py:5849: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2024-12-19 09:29:53 | INFO | fairseq_cli.eval_lm | 1 </s> [-1.831185]	prejudice [-17.711842]	one [-6.389266]	</s> [-2.450813]	slap [-17.890636]	your [-8.696891]	</s> [-1.889392]	slap [-18.281603]	hundred [-8.603020]	</s> [-1.213716]	slap [-18.252115]	my [-8.759484]	</s> [-1.585033]	bring [-18.843941]	your [-8.567203]	</s> [-1.855869]	bring [-18.923527]	one [-9.114058]	</s> [-1.968230]	blackguard [-19.811646]	hundred [-8.855661]	</s> [-1.291668]	blackguard [-19.651110]	the [-9.720759]	</s> [-1.216977]	blackguard [-19.565052]	a [-8.979000]	</s> [-1.397329]	fall [-18.097874]	one [-9.419055]	</s> [-1.919001]	fall [-17.937531]	your [-9.564184]	</s> [-1.798367]	interfere [-17.910696]	hundred [-9.352606]	</s> [-1.286505]	interfere [-17.915054]	one [-9.235023]	</s> [-1.870482]	interfere [-17.833075]	an [-9.751093]	</s> [-1.279116]	interfere [-17.834101]	a [-9.599900]	</s> [-1.235636]	prescribe [-18.931732]	my [-8.192937]	</s> [-1.472350]	prescribe [-19.220814]	a [-8.402506]	</s> [-1.202443]	racketeer [-18.650351]	my [-8.278383]	</s> [-1.497739]	racketeer [-18.585838]	the [-9.481440]	</s> [-1.485084]	number [-17.000496]	hundred [-8.537181]	</s> [-1.431817]	number [-17.155659]	one [-9.471627]	</s> [-1.972092]	number [-17.146837]	an [-9.494606]	</s> [-1.484533]	secularize [-18.202366]	one [-8.969581]	</s> [-2.055542]	secularize [-18.407768]	the [-9.825086]	</s> [-1.613297]	commercialize [-17.017542]	one [-8.721825]	</s> [-1.958081]	commercialize [-16.977003]	your [-8.723440]	</s> [-1.625090]	commercialize [-16.993446]	a [-8.544501]	</s> [-1.316520]	jeopardize [-17.630182]	my [-8.615691]	</s> [-1.573277]	crash [-17.669165]	one [-8.236415]	</s> [-1.901777]	crash [-17.638166]	an [-9.327662]	</s> [-1.231228]	shove [-17.548592]	one [-8.193727]	</s> [-2.064235]	shove [-17.474335]	your [-8.236575]	</s> [-1.684654]	fertilize [-18.320873]	the [-9.649191]	</s> [-1.602193]	fertilize [-18.482183]	one [-9.038239]	</s> [-1.977650]	fertilize [-18.496977]	a [-9.376206]	</s> [-1.346787]	fertilize [-18.348938]	hundred [-8.585867]	</s> [-1.452092]	intermarry [-19.107584]	the [-10.159394]	</s> [-1.414616]	misconduct [-17.799934]	the [-9.049620]	</s> [-1.444717]	vault [-18.367062]	hundred [-8.958537]	</s> [-1.250378]	follow [-18.470388]	one [-9.024188]	</s> [-1.945732]	square [-16.558588]	an [-8.087630]	</s> [-1.186195]	buttonhole [-19.249018]	your [-9.163877]	</s> [-1.601372]	predetermine [-18.833641]	your [-9.677463]	</s> [-1.473842]	predetermine [-18.951906]	one [-9.220543]	</s> [-1.912162]	replenish [-18.112213]	one [-9.062439]	</s> [-1.920329]	replenish [-18.119259]	my [-8.802937]	</s> [-1.531374]	replenish [-18.232103]	your [-9.311936]	</s> [-1.620339]	replenish [-18.200418]	hundred [-9.142353]	</s> [-1.216076]	promenade [-17.694937]	hundred [-9.091165]	</s> [-1.199838]	promenade [-17.522478]	an [-9.440084]	</s> [-1.433099]	promenade [-17.718142]	the [-9.483774]	</s> [-1.594616]	pitchfork [-18.400297]	my [-8.466418]	</s> [-1.443476]	pitchfork [-18.157263]	the [-9.581597]	</s> [-1.433760]	pitchfork [-18.138435]	a [-9.434912]	</s> [-1.446579]	power [-18.552410]	your [-9.394491]	</s> [-1.784450]	power [-18.654423]	the [-9.824584]	</s> [-1.625572]	power [-18.610008]	hundred [-8.850164]	</s> [-1.270477]	hero [-18.593517]	one [-8.560868]	</s> [-1.857992]	hero [-18.561808]	my [-9.092830]	</s> [-1.493537]	hero [-18.614286]	the [-10.203944]	</s> [-1.493371]	misbehave [-19.030451]	the [-8.287331]	</s> [-1.428075]	misbehave [-19.169651]	an [-8.695423]	</s> [-1.185396]	undervalue [-18.221535]	one [-8.375245]	</s> [-1.859800]	undervalue [-18.148489]	a [-8.710631]	</s> [-1.305642]	burlesque [-18.500200]	one [-9.474599]	</s> [-1.895080]	burlesque [-18.643808]	hundred [-8.916737]	</s> [-1.291477]	burlesque [-18.324215]	my [-9.100229]	</s> [-1.399754]	burlesque [-18.333378]	an [-10.097228]	</s> [-1.253040]	burlesque [-18.450487]	your [-9.279238]	</s> [-1.616378]	provision [-17.314732]	one [-9.114624]	</s> [-1.982444]	provision [-17.381329]	an [-10.372484]	</s> [-1.328717]	dress [-17.702108]	hundred [-8.184581]	</s> [-1.422289]	dress [-17.863571]	your [-8.221992]	</s> [-1.716551]	slaughter [-18.839392]	a [-8.606191]	</s> [-1.650967]	slaughter [-18.895123]	my [-8.333328]	</s> [-1.568890]	slaughter [-18.760763]	your [-8.936656]	</s> [-1.644954]
2024-12-19 09:29:53 | INFO | fairseq_cli.eval_lm | 0 stand [-14.431863]	one [-7.320823]	</s> [-1.947636]	key [-17.103033]	hundred [-8.315433]	</s> [-1.402269]	rich [-14.303693]	an [-3.366122]	</s> [-1.298224]	rich [-14.538052]	a [-3.436957]	</s> [-1.415774]	rich [-14.529487]	your [-3.112620]	</s> [-1.680435]	rubber [-18.283533]	the [-8.801546]	</s> [-1.571214]	rubber [-18.282070]	an [-9.649289]	</s> [-1.282602]	weasel [-18.526466]	a [-8.204770]	</s> [-1.106675]	weasel [-18.373623]	my [-8.392753]	</s> [-1.315897]	weasel [-18.486345]	an [-9.108182]	</s> [-1.309742]	weasel [-18.257418]	the [-9.509830]	</s> [-1.551780]	choke [-18.567179]	the [-9.057404]	</s> [-1.464013]	choke [-18.571505]	hundred [-8.243361]	</s> [-1.151432]	choke [-18.594646]	your [-8.703288]	</s> [-1.563804]	gallivant [-18.648457]	the [-8.928137]	</s> [-1.422551]	gallivant [-18.515665]	a [-8.920735]	</s> [-1.248922]	gallivant [-18.866911]	my [-8.162820]	</s> [-1.347869]	break [-17.651869]	your [-8.850761]	</s> [-1.570924]	break [-17.383175]	a [-9.385825]	</s> [-1.408471]	break [-17.410696]	hundred [-8.514513]	</s> [-1.246847]	criticise [-17.867384]	your [-8.686466]	</s> [-1.663284]	criticise [-17.933893]	the [-9.847803]	</s> [-1.673297]	criticise [-17.823572]	a [-9.417162]	</s> [-1.779390]	disembowel [-18.426987]	a [-9.612236]	</s> [-1.701452]	introvert [-18.720310]	your [-9.033675]	</s> [-1.771437]	introvert [-18.675522]	the [-10.107625]	</s> [-1.609144]	introvert [-18.752718]	an [-9.856120]	</s> [-1.210553]	get [-18.212214]	hundred [-8.648316]	</s> [-1.325096]	get [-18.124516]	a [-8.616087]	</s> [-1.310830]	come [-19.731966]	an [-8.712454]	</s> [-1.178184]	come [-19.875111]	your [-8.524709]	</s> [-1.722006]	smooth [-17.918646]	my [-8.415232]	</s> [-1.551991]	smooth [-17.742472]	one [-8.669785]	</s> [-1.990713]	smooth [-17.906305]	a [-9.290493]	</s> [-1.564940]	smooth [-17.833250]	hundred [-8.562439]	</s> [-1.269183]	smooth [-17.762896]	an [-9.637431]	</s> [-1.189805]	disrespect [-17.921537]	one [-7.966888]	</s> [-2.003284]	disrespect [-17.950294]	your [-8.887529]	</s> [-1.567357]	disrespect [-17.909630]	a [-8.331549]	</s> [-1.520294]	disrespect [-18.039806]	the [-9.002622]	</s> [-1.612651]	wheelbarrow [-17.576700]	a [-8.985960]	</s> [-1.327244]	wheelbarrow [-17.604790]	the [-9.832441]	</s> [-1.498657]	influence [-17.782421]	an [-10.092360]	</s> [-1.137072]	influence [-17.699415]	one [-8.862164]	</s> [-1.914489]	influence [-17.949070]	hundred [-9.088485]	</s> [-1.110782]	commingle [-18.649252]	one [-8.471002]	</s> [-1.971103]	commingle [-18.801523]	hundred [-8.181802]	</s> [-1.134994]	commingle [-18.785336]	a [-8.828840]	</s> [-1.372104]	rustle [-17.843229]	your [-8.866136]	</s> [-1.734130]	rustle [-17.671688]	an [-9.584139]	</s> [-1.482189]	constrict [-18.850266]	an [-9.693567]	</s> [-1.559205]	constrict [-18.957092]	a [-9.329060]	</s> [-1.562432]	constrict [-18.993237]	your [-9.090576]	</s> [-1.604228]	keep [-18.091181]	my [-9.025202]	</s> [-1.497162]	keep [-18.257633]	a [-9.676592]	</s> [-1.574364]	keep [-18.404051]	your [-9.050138]	</s> [-1.800657]	keep [-18.465084]	an [-9.702143]	</s> [-1.342890]	run [-16.303667]	an [-5.646896]	</s> [-1.166650]	run [-16.152969]	a [-5.615323]	</s> [-1.564358]	back [-16.140491]	a [-4.186043]	</s> [-1.634797]	back [-16.237419]	hundred [-3.603803]	</s> [-1.202585]	back [-16.375740]	an [-3.375698]	</s> [-1.247104]	dillydally [-18.148771]	a [-9.405532]	</s> [-1.545806]	headquarter [-18.501333]	the [-8.795450]	</s> [-1.535221]	headquarter [-18.506815]	my [-8.007518]	</s> [-1.511015]	headquarter [-18.631031]	your [-8.016341]	</s> [-1.634539]	mispronounce [-17.146532]	your [-8.181553]	</s> [-1.585066]	mispronounce [-16.982056]	one [-7.732907]	</s> [-1.915992]	mispronounce [-17.082842]	the [-8.985437]	</s> [-1.501151]	still [-17.752592]	my [-8.401448]	</s> [-1.589308]	still [-17.855522]	the [-9.415931]	</s> [-1.668258]	still [-17.833303]	your [-8.718353]	</s> [-1.785486]	apologize [-18.865383]	my [-8.617828]	</s> [-1.589055]	apologize [-18.963263]	the [-9.808511]	</s> [-1.633579]	apologize [-19.075920]	hundred [-9.045156]	</s> [-1.294383]	apologize [-18.934271]	a [-9.473240]	</s> [-1.338610]	apologize [-19.022669]	your [-9.528773]	</s> [-1.658209]	decentralize [-18.114298]	a [-9.192058]	</s> [-1.334170]	booby [-17.405567]	hundred [-8.406385]	</s> [-1.192201]	booby [-17.521280]	the [-9.539968]	</s> [-1.583389]	booby [-17.474974]	one [-8.814502]	</s> [-1.988090]	overemphasize [-18.215912]	my [-8.528707]	</s> [-1.604179]	overemphasize [-18.294394]	a [-9.191677]	</s> [-1.604817]	overemphasize [-18.306969]	hundred [-8.643026]	</s> [-1.223078]	overemphasize [-18.306892]	the [-9.789414]	</s> [-1.559616]	soft [-15.995899]	one [-9.072261]	</s> [-1.928333]	soft [-16.145573]	the [-10.194155]	</s> [-1.539454]	soft [-16.157167]	an [-9.917877]	</s> [-1.258318]	interchange [-18.667059]	hundred [-8.915227]	</s> [-1.130522]	interchange [-18.800043]	your [-8.863400]	</s> [-1.695217]	interchange [-18.900320]	my [-8.986555]	</s> [-1.660125]	stanchion [-18.770081]	the [-9.631549]	</s> [-1.549051]	bump [-18.575432]	one [-10.000260]	</s> [-1.919333]	bump [-18.509058]	your [-9.318516]	</s> [-1.902735]	ginger [-19.553595]	an [-9.460173]	</s> [-1.684255]	ginger [-19.370502]	a [-9.361289]	</s> [-1.620008]	ginger [-19.501080]	hundred [-8.509570]	</s> [-1.225487]	crosscheck [-17.663607]	the [-9.657813]	</s> [-1.598354]	crosscheck [-17.670628]	hundred [-8.576090]	</s> [-1.335826]	crosscheck [-17.445044]	one [-8.628213]	</s> [-1.991079]	track [-17.361307]	my [-8.865256]	</s> [-1.620286]	track [-17.466135]	the [-10.115586]	</s> [-1.509561]	sneeze [-19.809097]	a [-9.387040]	</s> [-1.615690]	sneeze [-19.868017]	the [-10.379247]	</s> [-1.617313]	sneeze [-19.702705]	your [-9.727965]	</s> [-1.844517]	give [-16.282446]	the [-4.866650]	</s> [-1.655321]	give [-16.415777]	an [-3.648419]	</s> [-1.640481]	reemphasize [-18.131966]	a [-9.760033]	</s> [-1.551103]	reemphasize [-17.815674]	the [-9.554271]	</s> [-1.537091]	brutalize [-17.210972]	a [-8.362587]	</s> [-1.436556]	brutalize [-17.234106]	your [-8.243147]	</s> [-1.598407]	backtrack [-17.223478]	my [-8.536211]	</s> [-1.572813]	backtrack [-17.212086]	an [-9.990961]	</s> [-1.380869]	splash [-18.151747]	a [-9.120051]	</s> [-1.437774]	splash [-18.176823]	one [-8.834510]	</s> [-1.876786]	splash [-18.235207]	the [-9.727919]	</s> [-1.486480]	medium [-14.061378]	my [-2.696356]	</s> [-1.653644]	medium [-14.114934]	hundred [-2.828612]	</s> [-1.226365]	medium [-14.038242]	your [-2.898273]	</s> [-1.733596]	outbalance [-17.544016]	your [-8.736568]	</s> [-1.614249]	outbalance [-17.761799]	hundred [-9.070072]	</s> [-1.216542]	glamorize [-17.383617]	your [-9.251852]	</s> [-1.731207]	glamorize [-17.350142]	hundred [-8.758357]	</s> [-1.147036]	spearhead [-18.830284]	your [-10.305077]	</s> [-1.558037]	spearhead [-19.069134]	one [-9.626779]	</s> [-1.779881]	spearhead [-19.010050]	my [-9.502748]	</s> [-1.458845]	spearhead [-19.020754]	a [-9.819215]	</s> [-1.418042]	blaspheme [-17.545635]	an [-10.187761]	</s> [-1.304270]	blaspheme [-17.568247]	the [-9.398611]	</s> [-1.480506]	intercede [-19.159571]	your [-8.511393]	</s> [-1.676185]	intercede [-19.199776]	a [-8.536932]	</s> [-1.575719]	intercede [-19.355600]	hundred [-7.759921]	</s> [-1.224538]	intercede [-19.208555]	one [-7.679948]	</s> [-1.862218]	intercede [-19.245384]	my [-7.958052]	</s> [-1.440161]	distemper [-18.380888]	your [-9.664676]	</s> [-1.702703]	distemper [-18.495678]	a [-9.318303]	</s> [-1.440107]	distemper [-18.387903]	hundred [-7.983850]	</s> [-1.224235]	rediscover [-18.350653]	my [-8.284371]	</s> [-1.495306]	listen [-17.651249]	an [-9.968261]	</s> [-1.284771]	listen [-17.556854]	one [-7.979245]	</s> [-1.927118]	sweet [-13.354497]	my [-2.877457]	</s> [-1.416721]	bucket [-17.526382]	an [-9.505477]	</s> [-1.228124]	bucket [-17.545559]	hundred [-8.318899]	</s> [-1.316007]	bucket [-17.575335]	your [-8.419860]	</s> [-1.688777]	demagnetise [-18.327255]	my [-8.817912]	</s> [-1.477684]	demagnetise [-18.327087]	an [-10.815371]	</s> [-1.351739]	close [-17.600092]	hundred [-8.283201]	</s> [-1.218211]	close [-17.463173]	one [-7.974102]	</s> [-1.899913]	close [-17.514654]	a [-8.969376]	</s> [-1.709601]	dehumanize [-19.583141]	your [-8.985240]	</s> [-1.797014]	folk [-19.466614]	hundred [-9.134045]	</s> [-1.234177]	folk [-19.586054]	an [-10.494328]	</s> [-1.388785]	folk [-19.523108]	the [-9.983118]	</s> [-1.553996]	folk [-19.285469]	your [-9.290989]	</s> [-1.684558]	blind [-13.306047]	your [-2.796993]	</s> [-1.668757]	carry [-18.211580]	an [-9.796870]	</s> [-1.438942]	carry [-18.169535]	your [-8.757578]	</s> [-1.595424]	carry [-18.014984]	a [-9.296468]	</s> [-1.372711]	carry [-17.974756]	my [-8.127855]	</s> [-1.486446]	inconvenience [-17.929821]	your [-9.269054]	</s> [-1.685646]	inconvenience [-17.860558]	hundred [-8.868673]	</s> [-1.288503]	mountebank [-17.131084]	your [-8.114990]	</s> [-1.535461]	mountebank [-17.191706]	hundred [-7.285893]	</s> [-1.367137]	mountebank [-17.365335]	my [-7.091203]	</s> [-1.478878]	pressurize [-18.946489]	my [-8.257402]	</s> [-1.537269]	pressurize [-19.073132]	a [-8.346753]	</s> [-1.482850]	pressurize [-19.218416]	the [-8.869803]	</s> [-1.581305]	pressurize [-19.125679]	an [-9.971007]	</s> [-1.535975]	circumcise [-17.995827]	my [-9.212112]	</s> [-1.469367]	overcharge [-18.021566]	one [-8.153749]	</s> [-1.825161]	prejudice [-17.824720]	a [-8.953311]
2024-12-19 09:29:53 | INFO | fairseq_cli.eval_lm | Evaluated 741 tokens in 0.8s (901.32 tokens/s)
2024-12-19 09:29:53 | INFO | fairseq_cli.eval_lm | Loss (base 2): 13.5772, Perplexity: 12222.02
