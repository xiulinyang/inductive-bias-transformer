2024-12-19 09:54:04 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2024-12-19 09:54:06 | INFO | fairseq_cli.eval_lm | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'checkpoints/grammar41exp2_permutation/7-transformer/checkpoint_best.pt', 'post_process': None, 'quiet': True, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': True, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': None, 'task': {'_name': 'language_modeling', 'data': 'data-bin/grammar41exp2_permutation/correct_7-dataset', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2024-12-19 09:54:06 | INFO | fairseq.tasks.language_modeling | dictionary: 1136 types
2024-12-19 09:54:06 | INFO | fairseq_cli.eval_lm | loading model(s) from checkpoints/grammar41exp2_permutation/7-transformer/checkpoint_best.pt
/workspace/artificial-languages/fairseq/fairseq/checkpoint_utils.py:340: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state = torch.load(f, map_location=torch.device("cpu"))
2024-12-19 09:54:09 | INFO | fairseq_cli.eval_lm | num. model params: 10,038,784
2024-12-19 09:54:09 | INFO | fairseq.data.data_utils | loaded 222 examples from: data-bin/grammar41exp2_permutation/correct_7-dataset/test
2024-12-19 09:54:09 | INFO | fairseq_cli.eval_lm | data-bin/grammar41exp2_permutation/correct_7-dataset test 2 examples
2024-12-19 09:54:09 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-12-19 09:54:09 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True
2024-12-19 09:54:09 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False
2024-12-19 09:54:09 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1
/opt/conda/envs/art/lib/python3.9/site-packages/torch/nn/functional.py:5849: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2024-12-19 09:54:10 | INFO | fairseq_cli.eval_lm | 1 </s> [-1.773024]	buttonhole [-20.159176]	an [-7.509562]	</s> [-2.431662]	buttonhole [-20.304630]	the [-7.218862]	</s> [-1.404846]	run [-16.890505]	my [-5.905098]	</s> [-1.941743]	run [-16.756432]	an [-7.346610]	</s> [-2.205672]	apologize [-18.980635]	one [-9.448743]	</s> [-2.320364]	apologize [-18.885122]	a [-9.448783]	</s> [-1.885636]	medium [-14.101002]	the [-1.897866]	</s> [-1.324019]	medium [-14.080368]	my [-2.146820]	</s> [-1.813460]	replenish [-18.555527]	an [-8.553825]	</s> [-1.939534]	replenish [-18.680775]	hundred [-9.169112]	</s> [-2.067131]	replenish [-18.572676]	my [-8.000669]	</s> [-1.401430]	stanchion [-18.604399]	an [-9.034794]	</s> [-1.662307]	stanchion [-18.543810]	hundred [-8.874791]	</s> [-2.108446]	stanchion [-18.689383]	my [-7.675395]	</s> [-1.628283]	interfere [-19.502113]	one [-8.287748]	</s> [-2.038072]	outbalance [-18.201799]	an [-9.400888]	</s> [-1.969065]	outbalance [-18.501602]	your [-9.613867]	</s> [-1.844378]	disrespect [-19.279058]	my [-7.735774]	</s> [-1.634480]	disrespect [-19.122986]	an [-9.195040]	</s> [-1.971335]	disrespect [-19.101433]	hundred [-9.160830]	</s> [-2.170499]	disrespect [-19.352570]	the [-7.820668]	</s> [-1.206891]	disrespect [-19.301304]	a [-9.246120]	</s> [-1.817855]	rubber [-18.432930]	the [-8.550534]	</s> [-1.089621]	rubber [-18.643454]	your [-9.549976]	</s> [-1.593118]	demagnetise [-19.106730]	one [-8.224848]	</s> [-2.300585]	misconduct [-18.400196]	an [-9.650099]	</s> [-2.079066]	misconduct [-18.278725]	your [-9.705734]	</s> [-1.532491]	constrict [-18.258463]	an [-8.730765]	</s> [-2.018540]	constrict [-17.990360]	a [-8.929204]	</s> [-1.984688]	constrict [-17.921585]	my [-7.709922]	</s> [-1.525458]	bucket [-17.787674]	your [-10.118771]	</s> [-1.728477]	bucket [-17.790358]	my [-8.231255]	</s> [-1.565633]	interchange [-18.318512]	my [-8.005398]	</s> [-1.677480]	interchange [-18.513391]	one [-8.392694]	</s> [-2.136511]	disembowel [-19.530514]	an [-9.667190]	</s> [-2.128720]	disembowel [-19.311255]	the [-8.928629]	</s> [-1.327637]	square [-16.761919]	your [-9.234110]	</s> [-1.902143]	distemper [-19.020643]	my [-7.762590]	</s> [-1.795271]	distemper [-18.967358]	a [-8.615019]	</s> [-1.992152]	distemper [-19.179482]	hundred [-8.563142]	</s> [-2.370430]	commercialize [-18.293018]	my [-8.116102]	</s> [-1.703691]	commercialize [-18.155142]	an [-8.879461]	</s> [-1.961932]	fall [-18.607931]	one [-8.743810]	</s> [-2.167428]	pitchfork [-17.372175]	my [-7.911100]	</s> [-1.942104]	pitchfork [-17.509737]	hundred [-9.308448]	</s> [-2.382647]	pitchfork [-17.371128]	your [-9.604649]	</s> [-1.765553]	predetermine [-19.657663]	one [-8.612551]	</s> [-2.254121]	intellectualize [-19.418951]	your [-9.329417]	</s> [-1.695762]	intellectualize [-19.289307]	one [-8.276350]	</s> [-2.333534]	fertilize [-18.268879]	a [-9.549793]	</s> [-2.119212]	fertilize [-18.346315]	my [-7.913258]	</s> [-1.901958]
2024-12-19 09:54:10 | INFO | fairseq_cli.eval_lm | 0 introvert [-16.701916]	the [-4.868334]	</s> [-1.211784]	close [-18.029264]	one [-6.843351]	</s> [-2.169802]	close [-18.394003]	my [-7.392404]	</s> [-1.757429]	intercede [-18.293673]	an [-8.932455]	</s> [-2.091619]	folk [-18.865923]	your [-9.830818]	</s> [-1.750852]	folk [-18.940235]	one [-8.948567]	</s> [-2.246015]	folk [-18.893990]	hundred [-9.234591]	</s> [-2.193918]	slaughter [-18.143597]	a [-9.372940]	</s> [-2.094635]	slaughter [-17.706257]	an [-9.211521]	</s> [-2.043008]	slaughter [-17.910685]	one [-8.807321]	</s> [-2.185333]	break [-17.438070]	an [-9.523569]	</s> [-1.821538]	rich [-14.628275]	a [-4.338038]	</s> [-1.662266]	rich [-14.522764]	an [-4.881510]	</s> [-1.720894]	rich [-14.784450]	the [-2.984962]	</s> [-1.122353]	prejudice [-18.069670]	my [-8.046008]	</s> [-1.658793]	secularize [-18.460495]	your [-8.495790]	</s> [-1.650958]	secularize [-19.018902]	my [-7.323342]	</s> [-1.854461]	secularize [-19.116312]	hundred [-8.255108]	</s> [-2.174840]	secularize [-18.739529]	one [-8.348278]	</s> [-2.236921]	racketeer [-19.125010]	a [-9.194605]	</s> [-1.913535]	racketeer [-19.237724]	hundred [-8.813819]	</s> [-2.212821]	still [-18.814644]	my [-8.077301]	</s> [-1.584777]	still [-18.769512]	one [-8.620082]	</s> [-2.309306]	number [-17.772827]	a [-9.455902]	</s> [-1.884916]	number [-17.898874]	the [-8.605156]	</s> [-1.184988]	revitalise [-17.852385]	one [-8.881512]	</s> [-2.407454]	revitalise [-17.731220]	a [-9.214986]	</s> [-1.907211]	revitalise [-17.869270]	hundred [-9.540749]	</s> [-2.198188]	overspecialize [-18.733469]	your [-8.998079]	</s> [-2.039226]	overspecialize [-18.499784]	one [-8.366930]	</s> [-2.256307]	weird [-15.246210]	your [-2.911002]	</s> [-1.850437]	weird [-15.423086]	the [-2.411099]	</s> [-1.208262]	rediscover [-18.835846]	an [-9.052935]	</s> [-2.056257]	rediscover [-18.914022]	my [-7.863287]	</s> [-1.623435]	rediscover [-18.915455]	your [-9.430639]	</s> [-1.724816]	mispronounce [-17.830791]	your [-9.431177]	</s> [-1.897031]	mispronounce [-17.828495]	a [-8.811648]	</s> [-2.059442]	mispronounce [-17.863991]	the [-8.397152]	</s> [-1.330577]	overemphasize [-17.987249]	a [-8.775256]	</s> [-1.954960]	overemphasize [-18.243481]	one [-8.174165]	</s> [-2.369785]	choke [-18.655621]	an [-9.142737]	</s> [-1.988181]	choke [-18.403450]	your [-9.316415]	</s> [-1.687569]	choke [-18.051449]	hundred [-8.865307]	</s> [-2.117220]	crosscheck [-17.776751]	your [-10.187668]	</s> [-1.906046]	crosscheck [-18.164137]	hundred [-9.171446]	</s> [-2.363200]	crash [-18.317631]	the [-8.501175]	</s> [-1.337979]	splash [-18.719990]	an [-9.177343]	</s> [-1.931145]	splash [-18.785944]	the [-8.969818]	</s> [-1.133512]	splash [-18.778561]	hundred [-8.720661]	</s> [-2.265051]	splash [-18.845797]	one [-8.974450]	</s> [-2.330817]	spearhead [-18.739201]	an [-8.596639]	</s> [-2.128602]	spearhead [-18.667547]	your [-9.051588]	</s> [-2.028612]	spearhead [-18.730682]	my [-7.657945]	</s> [-1.808655]	influence [-18.231428]	your [-9.756269]	</s> [-1.876131]	influence [-18.380001]	an [-8.981944]	</s> [-2.227045]	influence [-18.621189]	one [-8.796263]	</s> [-2.386493]	jeopardize [-18.721977]	a [-8.556973]	</s> [-2.024945]	jeopardize [-18.430420]	your [-9.646015]	</s> [-1.552906]	jeopardize [-18.241610]	an [-8.666981]	</s> [-2.087739]	get [-18.913118]	hundred [-8.889313]	</s> [-2.371031]	dehumanize [-17.543112]	an [-8.528148]	</s> [-2.226752]	dehumanize [-17.551941]	the [-8.503810]	</s> [-1.485678]	dehumanize [-17.408768]	a [-9.643884]	</s> [-2.055008]	commingle [-18.036585]	hundred [-8.571366]	</s> [-2.433274]	commingle [-18.136887]	my [-7.763805]	</s> [-1.894691]	slap [-18.236589]	hundred [-8.500553]	</s> [-2.477219]	slap [-17.998507]	my [-7.865808]	</s> [-1.870603]	slap [-17.763245]	the [-8.049728]	</s> [-1.159923]	blaspheme [-18.125854]	my [-8.183385]	</s> [-1.899287]	blaspheme [-18.191830]	a [-9.546232]	</s> [-2.137949]	blaspheme [-17.969400]	the [-8.565027]	</s> [-1.428574]	back [-15.760077]	hundred [-6.876907]	</s> [-2.326692]	back [-15.933445]	one [-6.436323]	</s> [-2.403841]	keep [-18.326809]	your [-9.221146]	</s> [-2.090612]	follow [-17.783642]	an [-8.623372]	</s> [-2.289892]	follow [-17.807962]	hundred [-8.786242]	</s> [-2.373440]	follow [-17.722509]	a [-8.808747]	</s> [-1.972571]	blackguard [-18.345406]	one [-9.096682]	</s> [-2.144418]	listen [-18.060957]	hundred [-8.732176]	</s> [-2.209493]	burlesque [-18.144936]	my [-8.066707]	</s> [-1.789420]	shove [-17.788004]	an [-8.904308]	</s> [-2.058380]	provision [-17.180561]	an [-9.142018]	</s> [-2.043281]	provision [-17.386019]	one [-8.759817]	</s> [-2.310355]	ginger [-17.759407]	a [-9.954916]	</s> [-2.111042]	undervalue [-18.308537]	my [-7.592962]	</s> [-1.892966]	circumcise [-17.874924]	my [-8.072938]	</s> [-1.720511]	circumcise [-17.966373]	a [-9.083253]	</s> [-1.968218]	backtrack [-18.229126]	my [-8.460897]	</s> [-1.440576]	give [-16.854145]	an [-7.672614]	</s> [-1.800397]	gallivant [-18.118071]	my [-8.215289]	</s> [-1.514896]	gallivant [-18.219444]	hundred [-8.350631]	</s> [-2.238419]	gallivant [-18.145195]	a [-9.074499]	</s> [-2.015604]	gallivant [-17.901476]	the [-8.273955]	</s> [-1.217356]	privilege [-17.890404]	the [-8.874456]	</s> [-1.425973]	privilege [-17.827400]	your [-9.653616]	</s> [-1.884357]	privilege [-17.607330]	a [-9.431828]	</s> [-2.082013]	decentralize [-18.244045]	the [-8.857553]	</s> [-1.300152]	misbehave [-18.522638]	an [-9.625240]	</s> [-2.117069]	misbehave [-18.505142]	a [-9.706886]	</s> [-2.103363]	misbehave [-18.095556]	one [-8.868052]	</s> [-2.282885]	misbehave [-18.236917]	hundred [-9.123825]	</s> [-2.489495]	misbehave [-18.471577]	your [-9.557981]	</s> [-1.979376]	brutalize [-18.634033]	the [-7.761686]	</s> [-1.448312]	brutalize [-18.744274]	my [-7.732775]	</s> [-1.956737]	brutalize [-18.560019]	hundred [-7.952685]	</s> [-2.318036]	brutalize [-18.553854]	an [-8.821483]	</s> [-2.186479]	reemphasize [-18.684542]	one [-8.683204]	</s> [-2.333181]	smooth [-19.043829]	a [-9.036648]	</s> [-2.186651]	smooth [-18.613064]	one [-8.359256]	</s> [-2.205636]	dress [-18.471914]	hundred [-8.980784]	</s> [-2.411196]	dress [-18.345800]	one [-8.698935]	</s> [-2.308029]	rustle [-18.513660]	my [-7.848804]	</s> [-2.001838]	rustle [-18.454245]	your [-9.878015]	</s> [-1.899367]	rustle [-18.386501]	a [-9.155129]	</s> [-1.869964]	rustle [-18.462145]	one [-8.763913]	</s> [-2.290281]	wheelbarrow [-18.509020]	a [-9.337812]	</s> [-2.030485]	wheelbarrow [-18.434494]	an [-8.652768]	</s> [-2.189922]	wheelbarrow [-18.574953]	my [-7.893884]	</s> [-1.871454]	bring [-18.097063]	a [-9.248094]	</s> [-2.034333]	bring [-18.001963]	your [-9.368282]	</s> [-1.985529]	hydroplane [-17.942135]	hundred [-8.386707]	</s> [-2.339740]	hydroplane [-18.150127]	the [-8.490745]	</s> [-1.518627]	inconvenience [-19.093790]	hundred [-9.115822]	</s> [-2.305062]	inconvenience [-18.953129]	a [-9.421393]	</s> [-1.991406]	track [-18.611040]	the [-7.878226]	</s> [-1.395256]	mountebank [-18.271067]	one [-9.009375]	</s> [-2.256644]	mountebank [-18.203680]	my [-7.966792]	</s> [-2.061486]	mountebank [-18.230049]	your [-9.793104]	</s> [-1.761726]	dillydally [-19.313686]	my [-8.075416]	</s> [-2.014750]	dillydally [-19.343176]	an [-9.442826]	</s> [-2.269537]	overcharge [-18.572794]	one [-8.663073]	</s> [-2.309741]	overcharge [-18.451681]	an [-8.682831]	</s> [-2.379340]	sound [-18.890827]	my [-7.679470]	</s> [-2.141802]	sound [-18.943838]	one [-8.397969]	</s> [-2.447425]	sound [-18.825460]	an [-8.881291]	</s> [-2.233702]	pressurize [-18.166039]	your [-9.560638]	</s> [-1.902604]	soft [-16.853840]	one [-8.468819]	</s> [-2.382315]	soft [-16.941921]	your [-9.603024]	</s> [-2.044076]	soft [-16.783176]	the [-8.228336]	</s> [-1.487077]	promenade [-18.321850]	hundred [-8.774019]	</s> [-2.442003]	promenade [-18.444525]	the [-8.392465]	</s> [-1.477640]	sneeze [-17.302500]	my [-8.242775]	</s> [-2.162578]	booby [-18.037010]	a [-9.024984]	</s> [-2.193564]	carry [-17.586390]	one [-9.295653]	</s> [-2.391018]	carry [-17.739967]	the [-9.106798]	</s> [-1.592857]	carry [-17.554119]	my [-8.310521]	</s> [-1.944208]	carry [-17.537428]	an [-9.492989]	</s> [-2.124827]	weasel [-17.853703]	your [-9.506747]	</s> [-2.074732]	weasel [-17.737041]	hundred [-8.680322]	</s> [-2.481101]	weasel [-17.950693]	my [-7.754258]	</s> [-2.145439]	weasel [-17.874380]	an [-8.467421]	</s> [-2.314329]	glamorize [-18.448111]	your [-9.770760]	</s> [-2.180671]	glamorize [-18.631403]	my [-8.241519]	</s> [-2.123164]	glamorize [-18.446327]	hundred [-8.793904]	</s> [-2.430778]	headquarter [-18.059862]	the [-8.487079]	</s> [-1.416241]	come [-18.066990]	an [-8.951711]	</s> [-2.113582]	come [-18.046755]	my [-8.299443]	</s> [-1.948123]	criticise [-18.258831]	a [-8.957752]	</s> [-1.968459]	criticise [-18.180302]	my [-8.073114]	</s> [-1.651898]	key [-18.439159]	one [-8.733274]	</s> [-2.293683]	bump [-18.283861]	your [-9.939274]	</s> [-1.873770]	power [-18.266937]	your [-10.043897]	</s> [-1.832295]	intermarry [-17.885612]	a [-9.270217]	</s> [-2.088409]	hero [-18.025536]	my [-7.951042]	</s> [-2.054150]	hero [-18.122530]	your [-9.502931]	</s> [-2.084647]	hero [-18.127287]	a [-8.705135]	</s> [-2.145219]	vault [-18.697554]	your [-9.700974]	</s> [-2.038503]	vault [-18.688204]	one [-8.775233]	</s> [-2.298798]	prescribe [-18.048151]	your [-9.751527]	</s> [-1.804077]	prescribe [-17.860914]	an [-9.150249]	</s> [-2.195053]	buttonhole [-19.779575]	your [-9.892608]
2024-12-19 09:54:10 | INFO | fairseq_cli.eval_lm | Evaluated 666 tokens in 0.7s (914.52 tokens/s)
2024-12-19 09:54:10 | INFO | fairseq_cli.eval_lm | Loss (base 2): 13.7992, Perplexity: 14255.68
