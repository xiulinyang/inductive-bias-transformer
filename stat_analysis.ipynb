{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T02:23:10.802902Z",
     "start_time": "2025-01-21T02:23:10.788291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from numpy.ma.core import log10\n"
   ],
   "id": "f4885260294b2627",
   "outputs": [],
   "execution_count": 96
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Get unique bigram stats",
   "id": "f02969b45ae20676"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T02:47:25.850404Z",
     "start_time": "2025-01-21T02:47:25.842989Z"
    }
   },
   "cell_type": "code",
   "source": [
    "clo =[\"glim flugit\",\n",
    "\"flairb flugit gentif\",\n",
    "\"daffin clidam\",\n",
    "\"glim ka zup\",\n",
    "\"glim ka tombur bleggin\",\n",
    "\"flairb ka lapal bleggin gentif\",\n",
    "\"daffin ka tombur spad\",\n",
    "\"flairb zup\",\n",
    "\"daffin lapal nawg\",\n",
    "\"flairb tombur flugit spad\",\n",
    "\"flairb lapal spad\",\n",
    "\"bleggin spad\",\n",
    "\"ka lapal\",\n",
    "\"ka lapal flugit\",\n",
    "\"ka tombur nawg clidam\",\n",
    "\"ka lapal spad\",\n",
    "\"lapal nawg\",\n",
    "\"tombur bleggin gentif\",\n",
    "\"zup gentif\",\n",
    "\"glim nawg\",\n",
    "\"glim mawg spad\",\n",
    "\"glim clidam\",\n",
    "\"flairb ka tombur\",\n",
    "\"flairb ka zup nawg\",\n",
    "\"daffin ka zup flugit clidam\",\n",
    "\"glim ka lapal gentif\",\n",
    "\"daffin lapal\",\n",
    "\"glim zup bleggin\",\n",
    "\"daffin zup flugit spad\",\n",
    "\"daffin tombur clidam\",\n",
    "\"mawg gentif\",\n",
    "\"ka zup\",\n",
    "\"ka zup bleggin\",\n",
    "\"ka tombur mawg gentif\",\n",
    "\"ka zup spad\",\n",
    "\"tombur flugit\",\n",
    "\"zup mawg clidam\",\n",
    "\"lapal clidam\"]\n",
    "\n",
    "\n",
    "op = [\"glim flugit\",\n",
    "\"flairb flugit gentif\",\n",
    "\"daffin clidam\",\n",
    "\"glim tombur ka\",\n",
    "\"glim lapal ka bleggin\",\n",
    "\"flairb tombur ka bleggin gentif\",\n",
    "\"daffin tombur ka spad\",\n",
    "\"flairb ka\",\n",
    "\"daffin ka nawg\",\n",
    "\"flairb ka flugit spad\",\n",
    "\"flairb ka spad\",\n",
    "\"bleggin spad\",\n",
    "\"tombur ka\",\n",
    "\"lapal ka flugit\",\n",
    "\"tombur ka mawg clidam\",\n",
    "\"lapal ka spad\",\n",
    "\"ka nawg\",\n",
    "\"ka bleggin gentif\",\n",
    "\"ka gentif\",\n",
    "\"glim nawg\",\n",
    "\"glim mawg spad\",\n",
    "\"glim clidam\",\n",
    "\"flairb zup ka\",\n",
    "\"flairb lapal ka nawg\",\n",
    "\"daffin zup ka flugit clidam\",\n",
    "\"glim zup ka gentif\",\n",
    "\"daffin ka\",\n",
    "\"glim ka bleggin\",\n",
    "\"daffin ka flugit spad\",\n",
    "\"daffin ka clidam\",\n",
    "\"mawg gentif\",\n",
    "\"zup ka\",\n",
    "\"tombur ka bleggin\",\n",
    "\"zup ka nawg gentif\",\n",
    "\"lapal ka spad\",\n",
    "\"ka flugit\",\n",
    "\"ka mawg clidam\",\n",
    "\"ka clidam\"]\n"
   ],
   "id": "7eb4715109de912e",
   "outputs": [],
   "execution_count": 107
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T02:47:27.620765Z",
     "start_time": "2025-01-21T02:47:27.615835Z"
    }
   },
   "cell_type": "code",
   "source": [
    "random.seed(50)\n",
    "def get_bigrams(sents):\n",
    "    bigrams = [b for l in sents for b in zip(l.split(\" \")[:-1], l.split(\" \")[1:])]\n",
    "    bigram_perm = ['_'.join(list(x)) for x in bigrams if x[1]!='']\n",
    "    return bigram_perm\n"
   ],
   "id": "64ec14214361a7a1",
   "outputs": [],
   "execution_count": 108
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-21T02:47:28.089572Z",
     "start_time": "2025-01-21T02:47:28.084216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "grammar_file = 'grammar53exp1'\n",
    "grammar_file_pert = 'grammar53exp1_permutation'\n",
    "b_a = []\n",
    "b_p = []\n",
    "for i in range(1):\n",
    "    # sents = Path(f'data_gen/grammar/{grammar_file}/{grammar_file}/{str(i)}.trn').read_text().strip().split('\\n')\n",
    "    # sents_pert = Path(f'data_gen/grammar/{grammar_file_pert}/{grammar_file_pert}/{str(i)}.trn').read_text().strip().split('\\n')\n",
    "    sents = clo\n",
    "    sents_pert = op\n",
    "    bigrams = len(Counter(get_bigrams(sents)))\n",
    "    bigrams_pert = len(Counter(get_bigrams(sents_pert)))\n",
    "    b_a.append(bigrams)\n",
    "    b_p.append(bigrams_pert)\n",
    "    print(bigrams, bigrams_pert)\n",
    "\n",
    "    counter_a = Counter(get_bigrams(sents_pert))\n",
    "    counter_b = Counter(get_bigrams(sents))\n",
    "\n",
    "print(np.mean(b_a))\n",
    "print(np.mean(b_p))"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 36\n",
      "46.0\n",
      "36.0\n"
     ]
    }
   ],
   "execution_count": 109
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T02:23:06.920673Z",
     "start_time": "2025-01-21T02:23:06.915870Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "a5157f6c6ec9a164",
   "outputs": [],
   "execution_count": 94
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Calculate average transition probability",
   "id": "b8e10cc6294afdec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "be5734f0776099ff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:02:57.093235Z",
     "start_time": "2025-01-21T03:02:15.809923Z"
    }
   },
   "cell_type": "code",
   "source": [
    "grammar_file = 'gn_grammarexp2'\n",
    "grammar_file_pert = 'gn_grammarexp2_permutation'\n",
    "\n",
    "def get_trans_freq(bigram_pair, word):\n",
    "    return sum([y for x,y in bigram_pair.items() if x.split('_')[0]==word])\n",
    "\n",
    "def get_sent_biprob(s, bigram_pair):\n",
    "    bi_s = [bigrams['_'.join(x)]/get_trans_freq(bigram_pair, x[0]) for x in zip(s.split()[:-1], s.split()[1:])]\n",
    "    return bi_s\n",
    "\n",
    "for i in range(1):\n",
    "    bi_prob = []\n",
    "    bip_prob = []\n",
    "    # uncomment if you want to calculate the transition probablity of Getz & Newport (2019)\n",
    "    # sents = clo\n",
    "    # sents_pert = op\n",
    "    sents = Path(f'data_gen/grammar/{grammar_file}/{grammar_file}/{str(i)}.trn').read_text().strip().split('\\n')\n",
    "    sents_pert = Path(f'data_gen/grammar/{grammar_file_pert}/{grammar_file_pert}/{str(i)}.trn').read_text().strip().split('\\n')\n",
    "    bigrams = Counter(get_bigrams(sents))\n",
    "    bigrams_pert = Counter(get_bigrams(sents_pert))\n",
    "    for s, sp in tqdm(zip(sents, sents_pert)):\n",
    "        av_bi_prob = get_sent_biprob(s, bigrams)\n",
    "        bi_prob.extend(av_bi_prob)\n",
    "        av_bip_prob = get_sent_biprob(sp, bigrams_pert)\n",
    "        bip_prob.extend(av_bip_prob)  \n",
    "    avg_log_bi_prob = sum(-math.log(prob) for prob in bi_prob if prob > 0) / len(bi_prob)\n",
    "    avg_log_bip_prob = sum(-math.log(prob) for prob in bip_prob if prob > 0) / len(bip_prob)\n",
    "    assert len(bi_prob) == len(bip_prob)\n",
    "    print(avg_log_bi_prob, avg_log_bip_prob)\n",
    "        \n",
    "        \n",
    "    "
   ],
   "id": "5bf7ad3095350b3b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9500it [00:41, 230.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5341524732109044 0.9348941324607767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 116
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T01:39:51.451662Z",
     "start_time": "2025-01-21T01:39:51.423759Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "51d62bed9420c89a",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'log' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[32], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mlog\u001B[49m(\u001B[38;5;241m5\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'log' is not defined"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T02:31:15.831136Z",
     "start_time": "2025-01-21T02:31:15.314207Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "af5083316420f7db",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9500/9500 [00:00<00:00, 606722.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.283686886187573 3.139806868017776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9500/9500 [00:00<00:00, 611133.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.280469330003706 3.1358354870678844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9500/9500 [00:00<00:00, 589070.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2798950124435255 3.132767692928678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9500/9500 [00:00<00:00, 579306.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2822232173536285 3.1362694007186107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9500/9500 [00:00<00:00, 572317.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.278501945673701 3.129821687875135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9500/9500 [00:00<00:00, 544476.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2905025421602616 3.1478150691186118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9500/9500 [00:00<00:00, 532627.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.287343906337925 3.1481364520559834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9500/9500 [00:00<00:00, 534793.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.288983886492472 3.1300798537266754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9500/9500 [00:00<00:00, 529422.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.285000231936679 3.139836049582841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9500/9500 [00:00<00:00, 522096.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.285888192192987 3.1338768291532233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 101
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T17:55:38.973106Z",
     "start_time": "2025-04-15T17:55:38.511779Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "all_dep = pd.read_csv('open_close_dependent_all.tsv', sep='\\t').to_dict(orient='records')\n",
    "\n",
    "for x in all_dep:\n",
    "    if x['close_require_open_ratio']>0.5:\n",
    "        print(x)"
   ],
   "id": "8f4e93f70a62f779",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Lang': 'UD_Korean-Kaist', 'open_require_close': 67555, 'open_require_close_ratio': 0.3, 'open_stand_alone': 197990, 'open_stand_alone_ratio': 0.8, 'close_require_open': 39676, 'close_require_open_ratio': 0.8, 'close_stand_alone': 9634, 'close_stand_alone_ratio': 0.2, 'close_all': 51222, 'open_all': 258984}\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# ENTROPY",
   "id": "91ed56e6960789d6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T22:26:48.013791Z",
     "start_time": "2025-05-26T22:26:48.005268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "def load_rules(grammar_file):\n",
    "    new_rules = {}\n",
    "    reverse_rules = {}\n",
    "    change = {}\n",
    "    g_file = open(grammar_file, 'r')\n",
    "    lines = g_file.readlines()\n",
    "    for l in lines:\n",
    "        if l.startswith(('#', \" \", \"\\t\", \"\\n\")) or len(l) < 1:\n",
    "            continue\n",
    "        else:\n",
    "            if l.find(\"#\") != -1:\n",
    "                l = l[:l.find(\"#\")]\n",
    "            idx = -1\n",
    "            if len(l.rstrip().split(\"\\t\")) == 3:\n",
    "                weight, lhs, rhs = l.rstrip().split(\"\\t\")\n",
    "\n",
    "            elif len(l.rstrip().split(\"\\t\")) == 4:\n",
    "                weight, lhs, rhs, idx = l.rstrip().split(\"\\t\")\n",
    "\n",
    "            else:\n",
    "                raise ValueError('The grammar is not acceptable!')\n",
    "\n",
    "            if lhs not in new_rules.keys():\n",
    "                new_rules[lhs] = []\n",
    "            poss_rhs = new_rules[lhs]\n",
    "            poss_rhs.append([rhs, float(weight)])\n",
    "            if idx != -1:\n",
    "                change[lhs + \"\\t\" + rhs] = idx\n",
    "    for lhs, poss in new_rules.items():\n",
    "        total = 0\n",
    "        for rhs in poss:\n",
    "            total += rhs[1]\n",
    "        for rhs in poss:\n",
    "            rhs[1] /= total\n",
    "    rules = new_rules\n",
    "    sum_nonterminal_nodes = sorted(list(rules.keys()))\n",
    "    return rules, sum_nonterminal_nodes"
   ],
   "id": "bebb6716d20761e7",
   "outputs": [],
   "execution_count": 112
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T22:26:48.374652Z",
     "start_time": "2025-05-26T22:26:48.365301Z"
    }
   },
   "cell_type": "code",
   "source": [
    "closed_x,non_terminal_nodes = load_rules('data_gen/base-grammar.gr')\n",
    "open_x,_ =  load_rules('data_gen/base-grammar_open_x.gr')\n"
   ],
   "id": "ed0bdf353a2119dc",
   "outputs": [],
   "execution_count": 113
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T22:26:59.554770Z",
     "start_time": "2025-05-26T22:26:59.546691Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gn_closed_x, gn_nonterminal = load_rules('data_gen/gn_grammar.gr')\n",
    "gn_open_x,_ = load_rules('data_gen/gn_grammar_open_x.gr')\n"
   ],
   "id": "6524ab050bd15064",
   "outputs": [],
   "execution_count": 114
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T22:29:13.076851Z",
     "start_time": "2025-05-26T22:29:13.059001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "grammar41_closed_x, g41_nonterminal = load_rules('data_gen/base-grammar41.gr')\n",
    "grammar41_open_x, _ = load_rules('data_gen/base-grammar41_open_x.gr')"
   ],
   "id": "7227c9200ee58017",
   "outputs": [],
   "execution_count": 115
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T22:29:35.832791Z",
     "start_time": "2025-05-26T22:29:35.817024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "grammar53_closed_x, g53_nonterminal = load_rules('data_gen/base-grammar53.gr')\n",
    "grammar53_open_x, _ = load_rules('data_gen/base-grammar53_open_x.gr')"
   ],
   "id": "c9f518056144bd2c",
   "outputs": [],
   "execution_count": 116
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T22:17:22.878383Z",
     "start_time": "2025-05-26T22:17:22.863368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_characteristic_matrix(grammar, nonterminal_nodes):\n",
    "    characteristic_matrix = {x: {y: 0 for y in nonterminal_nodes} for x in nonterminal_nodes}\n",
    "    for left, right in grammar.items():\n",
    "        for right_hand in right:\n",
    "            right_hand_rule = right_hand[0].split()\n",
    "            \n",
    "            for r_node in right_hand_rule:\n",
    "                if r_node in characteristic_matrix[left]:\n",
    "                    characteristic_matrix[left][r_node] += Counter(right_hand_rule)[r_node]*right_hand[1]\n",
    "    return characteristic_matrix\n",
    "\n",
    "\n",
    "def get_column_vector(grammar):\n",
    "    h={}\n",
    "    for left, right in grammar.items():\n",
    "        probs = [x[-1] for x in right]\n",
    "        h[left] = -sum([p*math.log(p) for p in probs if p > 0])\n",
    "    return h\n",
    "\n",
    "def convert_dict_to_matrix(characteristic_matrix, nonterminal_nodes):\n",
    "    size = len(nonterminal_nodes)\n",
    "    node_to_index = {node: idx for idx, node in enumerate(nonterminal_nodes)}\n",
    "    matrix = np.zeros((size, size))\n",
    "    for row_node, row_dict in characteristic_matrix.items():\n",
    "        if row_node in node_to_index:\n",
    "            row_idx = node_to_index[row_node]\n",
    "            for col_node, value in row_dict.items():\n",
    "                if col_node in node_to_index:\n",
    "                    col_idx = node_to_index[col_node]\n",
    "                    matrix[row_idx, col_idx] = value\n",
    "    return matrix\n",
    "\n",
    "def convert_dict_to_vector(column_vector, nonterminal_nodes):\n",
    "    size = len(nonterminal_nodes)\n",
    "    vector = np.zeros((size, 1))\n",
    "    node_to_index = {node: idx for idx, node in enumerate(nonterminal_nodes)}\n",
    "    for left_rule, prob in column_vector.items():\n",
    "        vector[node_to_index[left_rule],0] = prob\n",
    "    return vector\n",
    "\n",
    "def get_pcfg_entropy(grammar, nonterminal_nodes):\n",
    "    characteristic_matrix = convert_dict_to_matrix(get_characteristic_matrix(grammar, nonterminal_nodes), nonterminal_nodes)\n",
    "    column_vector = convert_dict_to_vector(get_column_vector(grammar), nonterminal_nodes)\n",
    "    identity_matrix = np.eye(len(nonterminal_nodes))\n",
    "    h=np.linalg.inv(identity_matrix -characteristic_matrix)@column_vector\n",
    "    start_symbol_index = non_terminal_nodes.index('ROOT')  # Adjust 'S' to your start symbol\n",
    "    H = h[start_symbol_index][0]\n",
    "    return H\n"
   ],
   "id": "fb4fa18b109048f6",
   "outputs": [],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T22:24:19.747391Z",
     "start_time": "2025-05-26T22:24:19.681920Z"
    }
   },
   "cell_type": "code",
   "source": [
    "H_closed=get_pcfg_entropy(closed_x, non_terminal_nodes)\n",
    "H_open=get_pcfg_entropy(open_x, non_terminal_nodes)\n",
    "print(H_closed,H_open)"
   ],
   "id": "b3fcb803c14d0e8e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.794453557845024 25.401835481818587\n"
     ]
    }
   ],
   "execution_count": 110
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T22:23:30.713612Z",
     "start_time": "2025-05-26T22:23:30.677378Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gn_h_closed= get_pcfg_entropy(gn_closed_x, non_terminal_nodes)\n",
    "gn_h_open= get_pcfg_entropy(gn_open_x, non_terminal_nodes)\n",
    "print(gn_h_closed, gn_h_open)"
   ],
   "id": "31d0ea0fe21650f8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9444389791664403 2.9444389791664403\n"
     ]
    }
   ],
   "execution_count": 109
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T22:30:15.118591Z",
     "start_time": "2025-05-26T22:30:15.013798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "g41_h_closed = get_pcfg_entropy(grammar41_closed_x, g41_nonterminal)\n",
    "g41_h_open = get_pcfg_entropy(grammar41_open_x, g41_nonterminal)\n",
    "print(g41_h_closed, g41_h_open)"
   ],
   "id": "65a02e44885f0004",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.14650819619146 34.85369906149169\n"
     ]
    }
   ],
   "execution_count": 117
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T22:30:42.177868Z",
     "start_time": "2025-05-26T22:30:42.124488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "g53_h_closed = get_pcfg_entropy(grammar53_closed_x, g53_nonterminal)\n",
    "g53_h_open = get_pcfg_entropy(grammar53_open_x, g53_nonterminal)\n",
    "print(g53_h_closed, g53_h_open)"
   ],
   "id": "aaa12422712139ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.96176456515862 34.84424377944872\n"
     ]
    }
   ],
   "execution_count": 118
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Archive",
   "id": "346f3e7dbac7afce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T23:33:25.648766Z",
     "start_time": "2025-09-14T23:33:25.596270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "for i in range(10):\n",
    "    ws50 = Path(f'data_gen/grammar/grammar_close_then_open/grammar_close_then_open/{i}.dev').read_text().strip().split('\\n')\n",
    "    ws  = Path(f'data_gen/grammar/grammar_close_then_open_permutation/grammar_close_then_open_permutation/{i}.dev').read_text().strip().split('\\n')\n",
    "    ws150  = Path(f'data_gen/grammar/grammar_close_then_open_100/grammar_close_then_open_100/{i}.dev').read_text().strip().split('\\n')\n",
    "    vocabs =[]\n",
    "    vocab_p = []\n",
    "    vocab_150 = []\n",
    "    for w5, w, w150 in zip(ws, ws50, ws150):\n",
    "        # if len(w5.split()) != len(w.split()):\n",
    "        #     print(w5, w)\n",
    "        vocabs.extend(w5.split())\n",
    "        vocab_p.extend(w.split())\n",
    "        vocab_150.extend(w150.split())\n",
    "        \n",
    "    print(len(set(vocabs)), len(set(vocab_p)), len(set(vocab_150)))\n",
    "    "
   ],
   "id": "4af623c17e30d0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1014 1101 1485\n",
      "993 1103 1487\n",
      "1027 1120 1507\n",
      "998 1095 1480\n",
      "1012 1125 1512\n",
      "1013 1109 1490\n",
      "1013 1111 1495\n",
      "1028 1131 1515\n",
      "995 1099 1481\n",
      "1017 1120 1503\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-15T00:28:27.687824Z",
     "start_time": "2025-09-15T00:27:44.225624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from wuggy import WuggyGenerator\n",
    "\n",
    "g = WuggyGenerator()\n",
    "g.load(\"orthographic_english\")\n",
    "for match in g.generate_classic([\"an\", \"a\", \"the\", \"can\", \"that\", \"he\",\"she\"],ncandidates_per_sequence=30):\n",
    "    print(match[\"pseudoword\"])\n",
    "    print(type(match[\"pseudoword\"]))"
   ],
   "id": "64ff170528d1d3f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ap\n",
      "<class 'str'>\n",
      "ar\n",
      "<class 'str'>\n",
      "aw\n",
      "<class 'str'>\n",
      "ag\n",
      "<class 'str'>\n",
      "ab\n",
      "<class 'str'>\n",
      "en\n",
      "<class 'str'>\n",
      "au\n",
      "<class 'str'>\n",
      "ay\n",
      "<class 'str'>\n",
      "aj\n",
      "<class 'str'>\n",
      "ac\n",
      "<class 'str'>\n",
      "ao\n",
      "<class 'str'>\n",
      "ak\n",
      "<class 'str'>\n",
      "ax\n",
      "<class 'str'>\n",
      "av\n",
      "<class 'str'>\n",
      "ai\n",
      "<class 'str'>\n",
      "tha\n",
      "<class 'str'>\n",
      "que\n",
      "<class 'str'>\n",
      "whe\n",
      "<class 'str'>\n",
      "tho\n",
      "<class 'str'>\n",
      "thi\n",
      "<class 'str'>\n",
      "thu\n",
      "<class 'str'>\n",
      "fre\n",
      "<class 'str'>\n",
      "swe\n",
      "<class 'str'>\n",
      "sce\n",
      "<class 'str'>\n",
      "twe\n",
      "<class 'str'>\n",
      "dre\n",
      "<class 'str'>\n",
      "pre\n",
      "<class 'str'>\n",
      "sme\n",
      "<class 'str'>\n",
      "gle\n",
      "<class 'str'>\n",
      "wre\n",
      "<class 'str'>\n",
      "ske\n",
      "<class 'str'>\n",
      "ble\n",
      "<class 'str'>\n",
      "ple\n",
      "<class 'str'>\n",
      "sle\n",
      "<class 'str'>\n",
      "spe\n",
      "<class 'str'>\n",
      "kne\n",
      "<class 'str'>\n",
      "tre\n",
      "<class 'str'>\n",
      "gre\n",
      "<class 'str'>\n",
      "phe\n",
      "<class 'str'>\n",
      "fle\n",
      "<class 'str'>\n",
      "che\n",
      "<class 'str'>\n",
      "sve\n",
      "<class 'str'>\n",
      "dwe\n",
      "<class 'str'>\n",
      "gwe\n",
      "<class 'str'>\n",
      "ste\n",
      "<class 'str'>\n",
      "han\n",
      "<class 'str'>\n",
      "cas\n",
      "<class 'str'>\n",
      "lan\n",
      "<class 'str'>\n",
      "cun\n",
      "<class 'str'>\n",
      "cag\n",
      "<class 'str'>\n",
      "san\n",
      "<class 'str'>\n",
      "dan\n",
      "<class 'str'>\n",
      "cav\n",
      "<class 'str'>\n",
      "cah\n",
      "<class 'str'>\n",
      "cal\n",
      "<class 'str'>\n",
      "cai\n",
      "<class 'str'>\n",
      "caj\n",
      "<class 'str'>\n",
      "cau\n",
      "<class 'str'>\n",
      "cax\n",
      "<class 'str'>\n",
      "cak\n",
      "<class 'str'>\n",
      "cac\n",
      "<class 'str'>\n",
      "cao\n",
      "<class 'str'>\n",
      "cay\n",
      "<class 'str'>\n",
      "cin\n",
      "<class 'str'>\n",
      "cen\n",
      "<class 'str'>\n",
      "gan\n",
      "<class 'str'>\n",
      "kan\n",
      "<class 'str'>\n",
      "yan\n",
      "<class 'str'>\n",
      "jan\n",
      "<class 'str'>\n",
      "zan\n",
      "<class 'str'>\n",
      "frat\n",
      "<class 'str'>\n",
      "thot\n",
      "<class 'str'>\n",
      "thit\n",
      "<class 'str'>\n",
      "snat\n",
      "<class 'str'>\n",
      "quat\n",
      "<class 'str'>\n",
      "thut\n",
      "<class 'str'>\n",
      "thet\n",
      "<class 'str'>\n",
      "skat\n",
      "<class 'str'>\n",
      "blat\n",
      "<class 'str'>\n",
      "glat\n",
      "<class 'str'>\n",
      "wrat\n",
      "<class 'str'>\n",
      "thad\n",
      "<class 'str'>\n",
      "plat\n",
      "<class 'str'>\n",
      "smat\n",
      "<class 'str'>\n",
      "knat\n",
      "<class 'str'>\n",
      "thap\n",
      "<class 'str'>\n",
      "grat\n",
      "<class 'str'>\n",
      "phat\n",
      "<class 'str'>\n",
      "trat\n",
      "<class 'str'>\n",
      "cpat\n",
      "<class 'str'>\n",
      "rnat\n",
      "<class 'str'>\n",
      "xmat\n",
      "<class 'str'>\n",
      "crat\n",
      "<class 'str'>\n",
      "stat\n",
      "<class 'str'>\n",
      "ptat\n",
      "<class 'str'>\n",
      "mrat\n",
      "<class 'str'>\n",
      "dnat\n",
      "<class 'str'>\n",
      "czat\n",
      "<class 'str'>\n",
      "psat\n",
      "<class 'str'>\n",
      "tsat\n",
      "<class 'str'>\n",
      "hu\n",
      "<class 'str'>\n",
      "le\n",
      "<class 'str'>\n",
      "te\n",
      "<class 'str'>\n",
      "ce\n",
      "<class 'str'>\n",
      "fe\n",
      "<class 'str'>\n",
      "de\n",
      "<class 'str'>\n",
      "hy\n",
      "<class 'str'>\n",
      "ge\n",
      "<class 'str'>\n",
      "ve\n",
      "<class 'str'>\n",
      "je\n",
      "<class 'str'>\n",
      "ze\n",
      "<class 'str'>\n",
      "ke\n",
      "<class 'str'>\n",
      "qe\n",
      "<class 'str'>\n",
      "che\n",
      "<class 'str'>\n",
      "shi\n",
      "<class 'str'>\n",
      "sho\n",
      "<class 'str'>\n",
      "shu\n",
      "<class 'str'>\n",
      "fle\n",
      "<class 'str'>\n",
      "cre\n",
      "<class 'str'>\n",
      "gre\n",
      "<class 'str'>\n",
      "cle\n",
      "<class 'str'>\n",
      "sle\n",
      "<class 'str'>\n",
      "sha\n",
      "<class 'str'>\n",
      "spe\n",
      "<class 'str'>\n",
      "dre\n",
      "<class 'str'>\n",
      "pre\n",
      "<class 'str'>\n",
      "ble\n",
      "<class 'str'>\n",
      "tre\n",
      "<class 'str'>\n",
      "ste\n",
      "<class 'str'>\n",
      "ple\n",
      "<class 'str'>\n",
      "swe\n",
      "<class 'str'>\n",
      "que\n",
      "<class 'str'>\n",
      "twe\n",
      "<class 'str'>\n",
      "kne\n",
      "<class 'str'>\n",
      "fre\n",
      "<class 'str'>\n",
      "sme\n",
      "<class 'str'>\n",
      "whe\n",
      "<class 'str'>\n",
      "gle\n",
      "<class 'str'>\n",
      "sce\n",
      "<class 'str'>\n",
      "ske\n",
      "<class 'str'>\n",
      "wre\n",
      "<class 'str'>\n",
      "gwe\n",
      "<class 'str'>\n",
      "sve\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T20:37:41.401544Z",
     "start_time": "2025-09-18T20:37:41.361173Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "146169dd1539dffa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T20:37:42.306342Z",
     "start_time": "2025-09-18T20:37:42.304421Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "96a225846e8d7d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5b73b8a1e469a0af"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
