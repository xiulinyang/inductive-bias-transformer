{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T02:23:10.802902Z",
     "start_time": "2025-01-21T02:23:10.788291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from numpy.ma.core import log10\n"
   ],
   "id": "f4885260294b2627",
   "outputs": [],
   "execution_count": 96
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Get unique bigram stats",
   "id": "f02969b45ae20676"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T02:47:25.850404Z",
     "start_time": "2025-01-21T02:47:25.842989Z"
    }
   },
   "cell_type": "code",
   "source": [
    "clo =[\"glim flugit\",\n",
    "\"flairb flugit gentif\",\n",
    "\"daffin clidam\",\n",
    "\"glim ka zup\",\n",
    "\"glim ka tombur bleggin\",\n",
    "\"flairb ka lapal bleggin gentif\",\n",
    "\"daffin ka tombur spad\",\n",
    "\"flairb zup\",\n",
    "\"daffin lapal nawg\",\n",
    "\"flairb tombur flugit spad\",\n",
    "\"flairb lapal spad\",\n",
    "\"bleggin spad\",\n",
    "\"ka lapal\",\n",
    "\"ka lapal flugit\",\n",
    "\"ka tombur nawg clidam\",\n",
    "\"ka lapal spad\",\n",
    "\"lapal nawg\",\n",
    "\"tombur bleggin gentif\",\n",
    "\"zup gentif\",\n",
    "\"glim nawg\",\n",
    "\"glim mawg spad\",\n",
    "\"glim clidam\",\n",
    "\"flairb ka tombur\",\n",
    "\"flairb ka zup nawg\",\n",
    "\"daffin ka zup flugit clidam\",\n",
    "\"glim ka lapal gentif\",\n",
    "\"daffin lapal\",\n",
    "\"glim zup bleggin\",\n",
    "\"daffin zup flugit spad\",\n",
    "\"daffin tombur clidam\",\n",
    "\"mawg gentif\",\n",
    "\"ka zup\",\n",
    "\"ka zup bleggin\",\n",
    "\"ka tombur mawg gentif\",\n",
    "\"ka zup spad\",\n",
    "\"tombur flugit\",\n",
    "\"zup mawg clidam\",\n",
    "\"lapal clidam\"]\n",
    "\n",
    "\n",
    "op = [\"glim flugit\",\n",
    "\"flairb flugit gentif\",\n",
    "\"daffin clidam\",\n",
    "\"glim tombur ka\",\n",
    "\"glim lapal ka bleggin\",\n",
    "\"flairb tombur ka bleggin gentif\",\n",
    "\"daffin tombur ka spad\",\n",
    "\"flairb ka\",\n",
    "\"daffin ka nawg\",\n",
    "\"flairb ka flugit spad\",\n",
    "\"flairb ka spad\",\n",
    "\"bleggin spad\",\n",
    "\"tombur ka\",\n",
    "\"lapal ka flugit\",\n",
    "\"tombur ka mawg clidam\",\n",
    "\"lapal ka spad\",\n",
    "\"ka nawg\",\n",
    "\"ka bleggin gentif\",\n",
    "\"ka gentif\",\n",
    "\"glim nawg\",\n",
    "\"glim mawg spad\",\n",
    "\"glim clidam\",\n",
    "\"flairb zup ka\",\n",
    "\"flairb lapal ka nawg\",\n",
    "\"daffin zup ka flugit clidam\",\n",
    "\"glim zup ka gentif\",\n",
    "\"daffin ka\",\n",
    "\"glim ka bleggin\",\n",
    "\"daffin ka flugit spad\",\n",
    "\"daffin ka clidam\",\n",
    "\"mawg gentif\",\n",
    "\"zup ka\",\n",
    "\"tombur ka bleggin\",\n",
    "\"zup ka nawg gentif\",\n",
    "\"lapal ka spad\",\n",
    "\"ka flugit\",\n",
    "\"ka mawg clidam\",\n",
    "\"ka clidam\"]\n"
   ],
   "id": "7eb4715109de912e",
   "outputs": [],
   "execution_count": 107
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T02:47:27.620765Z",
     "start_time": "2025-01-21T02:47:27.615835Z"
    }
   },
   "cell_type": "code",
   "source": [
    "random.seed(50)\n",
    "def get_bigrams(sents):\n",
    "    bigrams = [b for l in sents for b in zip(l.split(\" \")[:-1], l.split(\" \")[1:])]\n",
    "    bigram_perm = ['_'.join(list(x)) for x in bigrams if x[1]!='']\n",
    "    return bigram_perm\n"
   ],
   "id": "64ec14214361a7a1",
   "outputs": [],
   "execution_count": 108
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-21T02:47:28.089572Z",
     "start_time": "2025-01-21T02:47:28.084216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "grammar_file = 'grammar53exp1'\n",
    "grammar_file_pert = 'grammar53exp1_permutation'\n",
    "b_a = []\n",
    "b_p = []\n",
    "for i in range(1):\n",
    "    # sents = Path(f'data_gen/grammar/{grammar_file}/{grammar_file}/{str(i)}.trn').read_text().strip().split('\\n')\n",
    "    # sents_pert = Path(f'data_gen/grammar/{grammar_file_pert}/{grammar_file_pert}/{str(i)}.trn').read_text().strip().split('\\n')\n",
    "    sents = clo\n",
    "    sents_pert = op\n",
    "    bigrams = len(Counter(get_bigrams(sents)))\n",
    "    bigrams_pert = len(Counter(get_bigrams(sents_pert)))\n",
    "    b_a.append(bigrams)\n",
    "    b_p.append(bigrams_pert)\n",
    "    print(bigrams, bigrams_pert)\n",
    "\n",
    "    counter_a = Counter(get_bigrams(sents_pert))\n",
    "    counter_b = Counter(get_bigrams(sents))\n",
    "\n",
    "print(np.mean(b_a))\n",
    "print(np.mean(b_p))"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 36\n",
      "46.0\n",
      "36.0\n"
     ]
    }
   ],
   "execution_count": 109
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T02:23:06.920673Z",
     "start_time": "2025-01-21T02:23:06.915870Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "a5157f6c6ec9a164",
   "outputs": [],
   "execution_count": 94
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Calculate average transition probability",
   "id": "b8e10cc6294afdec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "be5734f0776099ff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T03:02:57.093235Z",
     "start_time": "2025-01-21T03:02:15.809923Z"
    }
   },
   "cell_type": "code",
   "source": [
    "grammar_file = 'gn_grammarexp2'\n",
    "grammar_file_pert = 'gn_grammarexp2_permutation'\n",
    "\n",
    "def get_trans_freq(bigram_pair, word):\n",
    "    return sum([y for x,y in bigram_pair.items() if x.split('_')[0]==word])\n",
    "\n",
    "def get_sent_biprob(s, bigram_pair):\n",
    "    bi_s = [bigrams['_'.join(x)]/get_trans_freq(bigram_pair, x[0]) for x in zip(s.split()[:-1], s.split()[1:])]\n",
    "    return bi_s\n",
    "\n",
    "for i in range(1):\n",
    "    bi_prob = []\n",
    "    bip_prob = []\n",
    "    # uncomment if you want to calculate the transition probablity of Getz & Newport (2019)\n",
    "    # sents = clo\n",
    "    # sents_pert = op\n",
    "    sents = Path(f'data_gen/grammar/{grammar_file}/{grammar_file}/{str(i)}.trn').read_text().strip().split('\\n')\n",
    "    sents_pert = Path(f'data_gen/grammar/{grammar_file_pert}/{grammar_file_pert}/{str(i)}.trn').read_text().strip().split('\\n')\n",
    "    bigrams = Counter(get_bigrams(sents))\n",
    "    bigrams_pert = Counter(get_bigrams(sents_pert))\n",
    "    for s, sp in tqdm(zip(sents, sents_pert)):\n",
    "        av_bi_prob = get_sent_biprob(s, bigrams)\n",
    "        bi_prob.extend(av_bi_prob)\n",
    "        av_bip_prob = get_sent_biprob(sp, bigrams_pert)\n",
    "        bip_prob.extend(av_bip_prob)  \n",
    "    avg_log_bi_prob = sum(-math.log(prob) for prob in bi_prob if prob > 0) / len(bi_prob)\n",
    "    avg_log_bip_prob = sum(-math.log(prob) for prob in bip_prob if prob > 0) / len(bip_prob)\n",
    "    assert len(bi_prob) == len(bip_prob)\n",
    "    print(avg_log_bi_prob, avg_log_bip_prob)\n",
    "        \n",
    "        \n",
    "    "
   ],
   "id": "5bf7ad3095350b3b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9500it [00:41, 230.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5341524732109044 0.9348941324607767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 116
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T01:39:51.451662Z",
     "start_time": "2025-01-21T01:39:51.423759Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "51d62bed9420c89a",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'log' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[32], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mlog\u001B[49m(\u001B[38;5;241m5\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'log' is not defined"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T02:31:15.831136Z",
     "start_time": "2025-01-21T02:31:15.314207Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "af5083316420f7db",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9500/9500 [00:00<00:00, 606722.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.283686886187573 3.139806868017776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9500/9500 [00:00<00:00, 611133.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.280469330003706 3.1358354870678844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9500/9500 [00:00<00:00, 589070.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2798950124435255 3.132767692928678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9500/9500 [00:00<00:00, 579306.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2822232173536285 3.1362694007186107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9500/9500 [00:00<00:00, 572317.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.278501945673701 3.129821687875135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9500/9500 [00:00<00:00, 544476.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2905025421602616 3.1478150691186118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9500/9500 [00:00<00:00, 532627.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.287343906337925 3.1481364520559834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9500/9500 [00:00<00:00, 534793.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.288983886492472 3.1300798537266754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9500/9500 [00:00<00:00, 529422.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.285000231936679 3.139836049582841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9500/9500 [00:00<00:00, 522096.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.285888192192987 3.1338768291532233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 101
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T17:55:38.973106Z",
     "start_time": "2025-04-15T17:55:38.511779Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "all_dep = pd.read_csv('open_close_dependent_all.tsv', sep='\\t').to_dict(orient='records')\n",
    "\n",
    "for x in all_dep:\n",
    "    if x['close_require_open_ratio']>0.5:\n",
    "        print(x)"
   ],
   "id": "8f4e93f70a62f779",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Lang': 'UD_Korean-Kaist', 'open_require_close': 67555, 'open_require_close_ratio': 0.3, 'open_stand_alone': 197990, 'open_stand_alone_ratio': 0.8, 'close_require_open': 39676, 'close_require_open_ratio': 0.8, 'close_stand_alone': 9634, 'close_stand_alone_ratio': 0.2, 'close_all': 51222, 'open_all': 258984}\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# ENTROPY",
   "id": "91ed56e6960789d6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T22:26:48.013791Z",
     "start_time": "2025-05-26T22:26:48.005268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "def load_rules(grammar_file):\n",
    "    new_rules = {}\n",
    "    reverse_rules = {}\n",
    "    change = {}\n",
    "    g_file = open(grammar_file, 'r')\n",
    "    lines = g_file.readlines()\n",
    "    for l in lines:\n",
    "        if l.startswith(('#', \" \", \"\\t\", \"\\n\")) or len(l) < 1:\n",
    "            continue\n",
    "        else:\n",
    "            if l.find(\"#\") != -1:\n",
    "                l = l[:l.find(\"#\")]\n",
    "            idx = -1\n",
    "            if len(l.rstrip().split(\"\\t\")) == 3:\n",
    "                weight, lhs, rhs = l.rstrip().split(\"\\t\")\n",
    "\n",
    "            elif len(l.rstrip().split(\"\\t\")) == 4:\n",
    "                weight, lhs, rhs, idx = l.rstrip().split(\"\\t\")\n",
    "\n",
    "            else:\n",
    "                raise ValueError('The grammar is not acceptable!')\n",
    "\n",
    "            if lhs not in new_rules.keys():\n",
    "                new_rules[lhs] = []\n",
    "            poss_rhs = new_rules[lhs]\n",
    "            poss_rhs.append([rhs, float(weight)])\n",
    "            if idx != -1:\n",
    "                change[lhs + \"\\t\" + rhs] = idx\n",
    "    for lhs, poss in new_rules.items():\n",
    "        total = 0\n",
    "        for rhs in poss:\n",
    "            total += rhs[1]\n",
    "        for rhs in poss:\n",
    "            rhs[1] /= total\n",
    "    rules = new_rules\n",
    "    sum_nonterminal_nodes = sorted(list(rules.keys()))\n",
    "    return rules, sum_nonterminal_nodes"
   ],
   "id": "bebb6716d20761e7",
   "outputs": [],
   "execution_count": 112
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T22:26:48.374652Z",
     "start_time": "2025-05-26T22:26:48.365301Z"
    }
   },
   "cell_type": "code",
   "source": [
    "closed_x,non_terminal_nodes = load_rules('data_gen/base-grammar.gr')\n",
    "open_x,_ =  load_rules('data_gen/base-grammar_open_x.gr')\n"
   ],
   "id": "ed0bdf353a2119dc",
   "outputs": [],
   "execution_count": 113
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T22:26:59.554770Z",
     "start_time": "2025-05-26T22:26:59.546691Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gn_closed_x, gn_nonterminal = load_rules('data_gen/gn_grammar.gr')\n",
    "gn_open_x,_ = load_rules('data_gen/gn_grammar_open_x.gr')\n"
   ],
   "id": "6524ab050bd15064",
   "outputs": [],
   "execution_count": 114
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T22:29:13.076851Z",
     "start_time": "2025-05-26T22:29:13.059001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "grammar41_closed_x, g41_nonterminal = load_rules('data_gen/base-grammar41.gr')\n",
    "grammar41_open_x, _ = load_rules('data_gen/base-grammar41_open_x.gr')"
   ],
   "id": "7227c9200ee58017",
   "outputs": [],
   "execution_count": 115
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T22:29:35.832791Z",
     "start_time": "2025-05-26T22:29:35.817024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "grammar53_closed_x, g53_nonterminal = load_rules('data_gen/base-grammar53.gr')\n",
    "grammar53_open_x, _ = load_rules('data_gen/base-grammar53_open_x.gr')"
   ],
   "id": "c9f518056144bd2c",
   "outputs": [],
   "execution_count": 116
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T22:17:22.878383Z",
     "start_time": "2025-05-26T22:17:22.863368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_characteristic_matrix(grammar, nonterminal_nodes):\n",
    "    characteristic_matrix = {x: {y: 0 for y in nonterminal_nodes} for x in nonterminal_nodes}\n",
    "    for left, right in grammar.items():\n",
    "        for right_hand in right:\n",
    "            right_hand_rule = right_hand[0].split()\n",
    "            \n",
    "            for r_node in right_hand_rule:\n",
    "                if r_node in characteristic_matrix[left]:\n",
    "                    characteristic_matrix[left][r_node] += Counter(right_hand_rule)[r_node]*right_hand[1]\n",
    "    return characteristic_matrix\n",
    "\n",
    "\n",
    "def get_column_vector(grammar):\n",
    "    h={}\n",
    "    for left, right in grammar.items():\n",
    "        probs = [x[-1] for x in right]\n",
    "        h[left] = -sum([p*math.log(p) for p in probs if p > 0])\n",
    "    return h\n",
    "\n",
    "def convert_dict_to_matrix(characteristic_matrix, nonterminal_nodes):\n",
    "    size = len(nonterminal_nodes)\n",
    "    node_to_index = {node: idx for idx, node in enumerate(nonterminal_nodes)}\n",
    "    matrix = np.zeros((size, size))\n",
    "    for row_node, row_dict in characteristic_matrix.items():\n",
    "        if row_node in node_to_index:\n",
    "            row_idx = node_to_index[row_node]\n",
    "            for col_node, value in row_dict.items():\n",
    "                if col_node in node_to_index:\n",
    "                    col_idx = node_to_index[col_node]\n",
    "                    matrix[row_idx, col_idx] = value\n",
    "    return matrix\n",
    "\n",
    "def convert_dict_to_vector(column_vector, nonterminal_nodes):\n",
    "    size = len(nonterminal_nodes)\n",
    "    vector = np.zeros((size, 1))\n",
    "    node_to_index = {node: idx for idx, node in enumerate(nonterminal_nodes)}\n",
    "    for left_rule, prob in column_vector.items():\n",
    "        vector[node_to_index[left_rule],0] = prob\n",
    "    return vector\n",
    "\n",
    "def get_pcfg_entropy(grammar, nonterminal_nodes):\n",
    "    characteristic_matrix = convert_dict_to_matrix(get_characteristic_matrix(grammar, nonterminal_nodes), nonterminal_nodes)\n",
    "    column_vector = convert_dict_to_vector(get_column_vector(grammar), nonterminal_nodes)\n",
    "    identity_matrix = np.eye(len(nonterminal_nodes))\n",
    "    h=np.linalg.inv(identity_matrix -characteristic_matrix)@column_vector\n",
    "    start_symbol_index = non_terminal_nodes.index('ROOT')  # Adjust 'S' to your start symbol\n",
    "    H = h[start_symbol_index][0]\n",
    "    return H\n"
   ],
   "id": "fb4fa18b109048f6",
   "outputs": [],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T22:24:19.747391Z",
     "start_time": "2025-05-26T22:24:19.681920Z"
    }
   },
   "cell_type": "code",
   "source": [
    "H_closed=get_pcfg_entropy(closed_x, non_terminal_nodes)\n",
    "H_open=get_pcfg_entropy(open_x, non_terminal_nodes)\n",
    "print(H_closed,H_open)"
   ],
   "id": "b3fcb803c14d0e8e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.794453557845024 25.401835481818587\n"
     ]
    }
   ],
   "execution_count": 110
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T22:23:30.713612Z",
     "start_time": "2025-05-26T22:23:30.677378Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gn_h_closed= get_pcfg_entropy(gn_closed_x, non_terminal_nodes)\n",
    "gn_h_open= get_pcfg_entropy(gn_open_x, non_terminal_nodes)\n",
    "print(gn_h_closed, gn_h_open)"
   ],
   "id": "31d0ea0fe21650f8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9444389791664403 2.9444389791664403\n"
     ]
    }
   ],
   "execution_count": 109
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T22:30:15.118591Z",
     "start_time": "2025-05-26T22:30:15.013798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "g41_h_closed = get_pcfg_entropy(grammar41_closed_x, g41_nonterminal)\n",
    "g41_h_open = get_pcfg_entropy(grammar41_open_x, g41_nonterminal)\n",
    "print(g41_h_closed, g41_h_open)"
   ],
   "id": "65a02e44885f0004",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.14650819619146 34.85369906149169\n"
     ]
    }
   ],
   "execution_count": 117
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T22:30:42.177868Z",
     "start_time": "2025-05-26T22:30:42.124488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "g53_h_closed = get_pcfg_entropy(grammar53_closed_x, g53_nonterminal)\n",
    "g53_h_open = get_pcfg_entropy(grammar53_open_x, g53_nonterminal)\n",
    "print(g53_h_closed, g53_h_open)"
   ],
   "id": "aaa12422712139ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.96176456515862 34.84424377944872\n"
     ]
    }
   ],
   "execution_count": 118
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Archive",
   "id": "346f3e7dbac7afce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T21:43:09.871489Z",
     "start_time": "2025-05-26T21:43:09.826575Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def get_characteristic_matrix(grammar, nonterminal_nodes):\n",
    "    characteristic_matrix = {x: {y: 0.0 for y in nonterminal_nodes} for x in nonterminal_nodes}\n",
    "    for left in grammar:\n",
    "        for (rhs, prob) in grammar[left]:  \n",
    "            rhs_symbols = rhs.split()\n",
    "            # Count non-terminals in RHS\n",
    "            counts = {}\n",
    "            for symbol in nonterminal_nodes:\n",
    "                counts[symbol] = rhs_symbols.count(symbol)\n",
    "            # Update matrix with prob * count\n",
    "            for symbol, cnt in counts.items():\n",
    "                characteristic_matrix[left][symbol] += prob * cnt\n",
    "    return characteristic_matrix\n",
    "\n",
    "def get_column_vector(grammar):\n",
    "    h0 = {}\n",
    "    for left in grammar:\n",
    "        probs = [rule[1] for rule in grammar[left]] \n",
    "        entropy = -sum(p * math.log(p) for p in probs if p > 0)\n",
    "        h0[left] = entropy\n",
    "    return h0\n",
    "\n",
    "def convert_dict_to_matrix(characteristic_matrix, nonterminal_nodes):\n",
    "    size = len(nonterminal_nodes)\n",
    "    node_to_index = {node: idx for idx, node in enumerate(nonterminal_nodes)}\n",
    "    matrix = np.zeros((size, size))\n",
    "    for row_node in nonterminal_nodes:\n",
    "        row_idx = node_to_index[row_node]\n",
    "        for col_node in nonterminal_nodes:\n",
    "            col_idx = node_to_index[col_node]\n",
    "            matrix[row_idx, col_idx] = characteristic_matrix[row_node][col_node]\n",
    "    return matrix\n",
    "\n",
    "def convert_dict_to_vector(column_vector, nonterminal_nodes):\n",
    "    size = len(nonterminal_nodes)\n",
    "    vector = np.zeros((size, 1))  # Column vector\n",
    "    node_to_index = {node: idx for idx, node in enumerate(nonterminal_nodes)}\n",
    "    for node in nonterminal_nodes:\n",
    "        vector[node_to_index[node], 0] = column_vector.get(node, 0)\n",
    "    return vector\n",
    "\n",
    "# Assuming non_terminal_nodes is a list of all non-terminals\n",
    "characteristic_matrix_closed = convert_dict_to_matrix(\n",
    "    get_characteristic_matrix(closed_x, non_terminal_nodes), non_terminal_nodes\n",
    ")\n",
    "characteristic_matrix_open = convert_dict_to_matrix(\n",
    "    get_characteristic_matrix(open_x, non_terminal_nodes), non_terminal_nodes\n",
    ")\n",
    "\n",
    "h0_closed = convert_dict_to_vector(get_column_vector(closed_x), non_terminal_nodes)\n",
    "h0_open = convert_dict_to_vector(get_column_vector(open_x), non_terminal_nodes)\n",
    "\n",
    "# Compute derivational entropy for closed grammar\n",
    "identity = np.eye(len(non_terminal_nodes))\n",
    "h_closed = np.linalg.inv(identity - characteristic_matrix_closed) @ h0_closed\n",
    "# Similarly for open grammar\n",
    "h_open = np.linalg.inv(identity - characteristic_matrix_open) @ h0_open\n",
    "\n",
    "# Extract entropy for the start symbol (e.g., 'S')\n",
    "start_symbol_index = non_terminal_nodes.index('S')  # Adjust 'S' to your start symbol\n",
    "H_closed = h_closed[start_symbol_index][0]\n",
    "H_open = h_open[start_symbol_index][0]"
   ],
   "id": "6bafffb9a772b6ae",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T21:43:13.538185Z",
     "start_time": "2025-05-26T21:43:13.530445Z"
    }
   },
   "cell_type": "code",
   "source": "H_closed",
   "id": "189b46d8f16e9856",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.794453557845024"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T21:43:17.569488Z",
     "start_time": "2025-05-26T21:43:17.564054Z"
    }
   },
   "cell_type": "code",
   "source": "H_open",
   "id": "aed86b0bc649b4b1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.401835481818587"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T22:19:56.685142Z",
     "start_time": "2025-05-26T22:19:56.679486Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rule_list = [\n",
    "    \"AXYBC\", \"XYBC\", \"AYC\", \"AY\", \"YB\",\n",
    "    \"AXYB\", \"ABC\", \"XYC\", \"AB\", \"YC\",\n",
    "    \"AXYC\", \"AXY\", \"XYB\", \"AC\", \"BC\",\n",
    "    \"AYBC\", \"AYB\", \"YBC\", \"XY\"\n",
    "]\n",
    "with open('data_gen/gn_grammar.gr', 'w') as f:\n",
    "    for r in rule_list:\n",
    "        print(list(r))\n",
    "        r_symbols = ' '.join(list(r))\n",
    "        f.write(f'1\\tROOT\\t{r_symbols}\\n')"
   ],
   "id": "52681faa1718cf06",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'X', 'Y', 'B', 'C']\n",
      "['X', 'Y', 'B', 'C']\n",
      "['A', 'Y', 'C']\n",
      "['A', 'Y']\n",
      "['Y', 'B']\n",
      "['A', 'X', 'Y', 'B']\n",
      "['A', 'B', 'C']\n",
      "['X', 'Y', 'C']\n",
      "['A', 'B']\n",
      "['Y', 'C']\n",
      "['A', 'X', 'Y', 'C']\n",
      "['A', 'X', 'Y']\n",
      "['X', 'Y', 'B']\n",
      "['A', 'C']\n",
      "['B', 'C']\n",
      "['A', 'Y', 'B', 'C']\n",
      "['A', 'Y', 'B']\n",
      "['Y', 'B', 'C']\n",
      "['X', 'Y']\n"
     ]
    }
   ],
   "execution_count": 100
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T20:56:58.266891Z",
     "start_time": "2025-09-14T20:56:58.233696Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "for i in range(10):\n",
    "    ws50 = Path(f'data_gen/grammar/grammar_close_then_open_50/grammar_close_then_open_50/{i}.dev').read_text().strip().split('\\n')\n",
    "    ws  = Path(f'data_gen/grammar/grammar_close_then_open/grammar_close_then_open/{i}.dev').read_text().strip().split('\\n')\n",
    "    for w5, w in zip(ws, ws50):\n",
    "        if len(w5.split()) != len(w.split()):\n",
    "            print(w5, w)"
   ],
   "id": "4af623c17e30d0",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "64ff170528d1d3f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
